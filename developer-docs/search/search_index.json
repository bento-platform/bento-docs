{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Bento Docs","text":"<p>This repository hosts the versioned documentation for the Bento portal, built with MkDocs and Mike, and deployed to GitHub Pages.</p>"},{"location":"#installation","title":"Installation","text":"<p>Install dependencies with Poetry:</p> <pre><code>poetry install\n</code></pre> <p>(Optional) Activate the Poetry shell:</p> <pre><code>poetry shell\n</code></pre>"},{"location":"#local-development","title":"Local Development","text":"<p>Preview the docs with live reload:</p> <pre><code>mkdocs serve\n</code></pre> <p>Build the static site:</p> <pre><code>mkdocs build --strict\n</code></pre>"},{"location":"#deployment","title":"Deployment","text":"<p>Manual deploy with Mike:</p> <pre><code>mike deploy &lt;version&gt; --push            # deploys docs under /&lt;version&gt;/ on gh-pages\nmike alias &lt;version&gt; latest --update-aliases --push  # update the latest alias\n</code></pre>"},{"location":"#cicd","title":"CI/CD","text":"<ul> <li>Release deploy: GitHub Actions workflow (<code>.github/workflows/deploy-docs.yml</code>) runs on GitHub Release to deploy the tagged version and update <code>latest</code>.</li> <li>Docs build &amp; test: CI workflow (<code>.github/workflows/ci.yml</code>) on push/PR builds docs (<code>mkdocs build --strict</code>) and runs tests.</li> </ul>"},{"location":"adding-services/","title":"Adding services to Bento","text":"<p>There are two types of services in Bento:</p> <ul> <li>Bento services, which have been developed by the Bento team specifically for the platform, and</li> <li>other services, which support the Bento services or provide additional platform features.</li> </ul>"},{"location":"adding-services/#aspects-to-consider-when-adding-any-service-to-bento","title":"Aspects to consider when adding any service to Bento","text":""},{"location":"adding-services/#environment-variables","title":"Environment variables","text":"<ul> <li>Service environment variables, used for configuring the image and some aspects of the service itself, should be added   to <code>etc/bento.env</code>. These variables typically include:</li> <li>Image</li> <li>Image version (tag)</li> <li>Container name template</li> <li>Service Docker network (Note: we typically give each service its own network, and add services to multiple     networks only as needed)</li> <li>Debugger ports</li> <li>Configuration environment variables, for setting up feature flags and passwords, should be added to   <code>etc/default_config.env</code> and the example files <code>etc/bento_deploy.env</code> and <code>etc/bento_dev.env</code>.</li> <li><code>etc/default_config.env</code> contains feature flags and \"empty definitions\" for passwords/secrets.</li> <li><code>etc/bento_deploy.env</code> is an example / template setup (to be copied to <code>local.env</code>) for a production deployment.</li> <li><code>etc/bento_dev.env</code> is an example / template setup (to be copied to <code>local.env</code>) for a development setup.</li> </ul>"},{"location":"adding-services/#container-setup","title":"Container setup","text":"<p>The service's Docker container must be set up via a Compose file in <code>lib/&lt;service&gt;/docker-compose.&lt;service&gt;.yaml</code>. This must then be included in the main <code>docker-compose.yaml</code> file, in the <code>include</code> block.</p> <p>The service's network (and potentially feature flag, if applicable), as well as container name and port environment variables must be added to the gateway compose file (<code>lib/gateway/docker-compose.gateway.yaml</code>) if the service is to be externally accessible.</p>"},{"location":"adding-services/#gateway-configuration","title":"Gateway configuration","text":"<p>As needed, a gateway NGINX config must be placed into <code>lib/gateway/&lt;public_services|services&gt;</code>.</p>"},{"location":"adding-services/#required-bentoctl-changes","title":"Required <code>bentoctl</code> changes","text":"<p>Inside the <code>py_bentoctl</code> Python module:</p> <ul> <li>If the service is locked behind a feature flag, add the feature (as an <code>BentoOptionalFeature</code> instance) to   <code>config.py</code>, modeling it after other definitions.</li> <li>Add the service image environment variables to the <code>service_image_vars</code> variable in <code>services.py</code>.</li> <li>If the service is not a Bento service (or does not have the <code>bento</code> user in the Docker image), add the service to the   <code>BENTO_USER_EXCLUDED_SERVICES</code> variable.</li> <li>In <code>other_helpers.py</code>:</li> <li>If the service has a data directory that needs to be initialized, add an entry to the <code>data_dir_vars</code> variable     in the <code>init_dirs(...)</code> function containing the name of the environment variable which points to the data volume     directory.</li> <li>Add any entry with the name of the environment variable storing the name of the Docker network to the <code>networks</code>     variable in the <code>init_docker(...)</code> function.</li> <li>If new certificates are needed, add new entries to the <code>init_self_signed_certs</code> function (for development purposes).</li> </ul>"},{"location":"adding-services/#documentation-changes","title":"Documentation changes","text":"<ul> <li>Make sure to add a note about how to set up the service for the first time to the   Installation guide, as well as the migration guide for the version the service is introduced in.</li> <li>If additional deployment steps are needed (i.e., new certificates), add a note to the   Deployment guide.</li> </ul>"},{"location":"adding-services/#additional-notes","title":"Additional notes","text":"<p>Non-Bento services MUST NOT be put into <code>etc/bento_services.json</code>; this file is for Bento services only (see below).</p>"},{"location":"adding-services/#additional-considerations-when-adding-new-bento-services","title":"Additional considerations when adding new Bento services","text":""},{"location":"adding-services/#user-and-base-image","title":"User and base image","text":"<p>It is expected that Bento services will use one of the Bento base images.</p> <p>These images provide a <code>bento</code> user, whose UID is set to the host user's UID.</p>"},{"location":"adding-services/#service-info-and-service-record-in-bento_servicesjson","title":"<code>/service-info</code> and service record in <code>bento_services.json</code>","text":"<p>Bento services MUST implement the GA4GH Service Info API. They must also be registered in the <code>etc/bento_services.json</code> file, which allows them to be loaded into the Bento Service Registry.</p> <p>Each entry of this file follows the format:</p> <pre><code>{\n  // ...\n   \"&lt;compose ID&gt;\": {\n     \"service_kind\": \"&lt;service kind&gt;\",\n     \"url_template\": \"{BENTO_PUBLIC_URL}/api/{service_kind}\",\n     \"repository\": \"git@github.com:bento-platform/&lt;...&gt;\"\n   },\n  // ...\n}\n</code></pre> <p>In this format:</p> <ul> <li><code>&lt;compose ID&gt;</code> is the key of the service in its <code>docker-compose.&lt;...&gt;.yaml</code> file</li> <li><code>&lt;service kind&gt;</code> is a special Bento-unique identifier for the service, allowing front ends to look up services.</li> <li>The <code>url_template</code> key is a template for the base URL used to access the service's API.</li> <li>The <code>repository</code> key is an SSH Git repository URL for the service code, so it can be cloned into the <code>repos</code> folder   for development.</li> </ul>"},{"location":"adding-services/#making-service-to-service-requests-go-through-the-gateway-dev","title":"Making service-to-service requests go through the gateway (dev)","text":"<p>Bento relies on three mechanisms to resolve hostnames to IP addresses:</p> <ul> <li>DNS records (production only)</li> <li><code>/etc/hosts</code> entries when in local dev</li> <li>For requests originating outside of the Docker networks (e.g. web browsers)</li> <li>Container names (production &amp; dev)</li> <li>When two containers are on the same Docker network and need to talk to each other directly</li> <li>Docker resolves a container's name to its IP on a Docker network</li> <li>e.g. Katsu can talk directly to DRS with <code>http://${BENTOV2_DRS_CONTAINER_NAME}:${BENTOV2_DRS_INTERNAL_PORT}</code></li> <li>Docker network aliases (dev only)</li> <li>When two services need to communicate with each other via the gateway only.</li> <li>In production, this is taken care of by DNS records</li> </ul> <p>When developing locally, some services may need to be interacted with strictly through the gateway. This is the case for Keycloak (auth) and Minio, as both services require a subdomain and HTTPS.</p> <p>As such, drop-box cannot use the Docker resolver in order to connect to Minio.</p> <p>Since we are in local, there is no DNS record to resolve Minio's domain, and the host's <code>/etc/hosts</code> entries will not be of help from the container's perspective.</p> <p>For these situations, we rely on Docker network aliases.</p> <p>Taking the Minio example, we need:</p> <ul> <li>Drop-Box to interact with Minio via the gateway</li> <li>DRS to interact with Minio via the gateway</li> </ul> <p>Enabling this is done by adding <code>${BENTO_MINIO_DOMAIN}</code> to the respective service networks aliases.</p> <p>This snippet comes from <code>docker-compose.dev.yaml</code>:</p> <pre><code>services:\n  gateway:\n    networks:\n      drop-box-net:\n        aliases:\n          - ${BENTOV2_DOMAIN}\n          - ${BENTOV2_PORTAL_DOMAIN}\n          - ${BENTOV2_AUTH_DOMAIN}\n          - ${BENTO_MINIO_DOMAIN}\n      drs-net:\n        aliases:\n          - ${BENTOV2_DOMAIN}\n          - ${BENTOV2_PORTAL_DOMAIN}\n          - ${BENTOV2_AUTH_DOMAIN}\n          - ${BENTO_MINIO_DOMAIN}\n</code></pre> <p>Doing so, we make sure that <code>${BENTO_MINIO_DOMAIN}</code> is resolved to the gateway for drop-box and DRS.</p>"},{"location":"bentoctl/","title":"<code>bentoctl</code>: the Bento deployment command line management tool","text":"<p>This command line tool offers a series of commands and parameters that are helpful to set up the Docker environment for  Bento services. It is designed to facilitate fast development and have better cross-platform compatibility versus the  old Makefile.</p>"},{"location":"bentoctl/#prerequisites","title":"Prerequisites","text":"<p>This CLI is specified by a Python module, <code>py_bentoctl</code>, launched by a Bash script,  <code>./bentoctl.bash</code>. The Bash wrapper loads various <code>.env</code> files to set up the Bento environment.</p> <p>The <code>bentoctl</code> script depends on Python packages, we recommend using a virtual environment for this.</p> <pre><code># Create a venv under ./env\npython3 -m venv env\n\n# Activate the python env\nsource env/bin/activate\n\n# Install dependencies\npip3 install -r requirements.txt\n</code></pre> <p>To make interacting with the CLI quicker, consider adding an alias for calling <code>bentoctl.bash</code>, putting the following in your <code>.bash_aliases</code>, <code>.bash_profile</code> or <code>.zshrc</code> file:</p> <p>Bash/ZSH: <code>alias bentoctl=\"./bentoctl.bash\"</code></p> <p>For a quick setup, use the following to append the alias to the file of your choice.</p> <pre><code># Optional: create an alias for bentoctl (run from project's root)\necho \"alias bentoctl=${PWD}/bentoctl.bash\" &gt; ~/.bash_aliases\n\n# Now RESTART your terminal and re-source the virtualenv, OR run:\nsource ~/.bash_aliases\n\n# Then, use your alias!\nbentoctl --help\n</code></pre>"},{"location":"bentoctl/#usage","title":"Usage","text":"<p>For an overview of <code>bentoctl</code>'s features, type the following from the root of the project:</p> <pre><code>./bentoctl.bash\n</code></pre> <p>Note: the flags <code>--debug, -d</code> are intended for interactive remote Python debugging of the <code>bentoctl</code> module  itself. See VSCode instructions or  PyCharm instructions for IDE setup.</p>"},{"location":"bentoctl/#next-steps","title":"Next steps","text":"<ul> <li>Installation</li> <li>Development</li> </ul>"},{"location":"deployment/","title":"Deployment","text":"<p>This section details the required steps to deploy Bento on a server and expose it to the internet. The instructions assume you have a server with a public IP and DNS records pointing to it for the domains you will use.</p> <p>A bento deployment usually has up to 4 domains or subdomains, this section uses the following examples:</p> <pre><code>BENTOV2_DOMAIN=bento.example.com\nBENTOV2_PORTAL_DOMAIN=portal.${BENTOV2_DOMAIN}\nBENTOV2_AUTH_DOMAIN=auth.${BENTOV2_DOMAIN}\nBENTOV2_CBIOPORTAL_DOMAIN=cbioportal.${BENTOV2_DOMAIN}\nBENTO_MINIO_DOMAIN=minio.${BENTOV2_DOMAIN}\n</code></pre> <p>For a real deployment, make sure that your <code>local.env</code> file uses valid domain names for which SSL certificates  can be obtained.</p>"},{"location":"deployment/#certificates-paths","title":"Certificates paths","text":"<p>In production mode, Bento must use valid SSL certificates instead of self-signed ones. Before requesting certificates, make sure that you override the following environment  variables in your <code>local.env</code> file.</p> <pre><code>BENTOV2_AUTH_FULLCHAIN_RELATIVE_PATH=/live/$BENTOV2_AUTH_DOMAIN/fullchain.pem\nBENTOV2_AUTH_PRIVKEY_RELATIVE_PATH=/live/$BENTOV2_AUTH_DOMAIN/privkey.pem\nBENTOV2_GATEWAY_INTERNAL_PORTAL_FULLCHAIN_RELATIVE_PATH=/live/$BENTOV2_PORTAL_DOMAIN/fullchain.pem\nBENTOV2_GATEWAY_INTERNAL_PORTAL_PRIVKEY_RELATIVE_PATH=/live/$BENTOV2_PORTAL_DOMAIN/privkey.pem\nBENTOV2_GATEWAY_INTERNAL_FULLCHAIN_RELATIVE_PATH=/live/$BENTOV2_DOMAIN/fullchain.pem\nBENTOV2_GATEWAY_INTERNAL_PRIVKEY_RELATIVE_PATH=/live/$BENTOV2_DOMAIN/privkey.pem\n</code></pre>"},{"location":"deployment/#obtain-certificates","title":"Obtain certificates","text":"<p>On a fresh Bento install, the initial SSL certificates can be obtained with a convenience script.</p> <pre><code>bash ./etc/scripts/init_certs_only.sh\n\n# Answer CertBot prompts\n# Does a --dry-run first\n\n# Check the certificates\nls ./certs/gateway/letsencrypt\nls ./certs/auth/letsencrypt\n</code></pre>"},{"location":"deployment/#renew-certificates","title":"Renew certificates","text":"<p>To renew the certificates after they are issued, use the convenience script made to this effect:</p> <pre><code>bash ./etc/scripts/renew_certs_and_redeploy.sh\n# Answer CertBot prompts\n# Does a --dry-run first\n\n# Check the certificates\nls ./certs/gateway/letsencrypt/live\nls ./certs/auth/letsencrypt/live\n</code></pre> <p>Note that this script will shutdown auth and gateway during the certificate renewal.</p>"},{"location":"deployment/#permanently-redirect-a-domain","title":"Permanently redirect a domain","text":"<p>If a Bento instance must use a new domain, the gateway can redirect requests from the old domain to the new one.  This is advised to prevent dead links, see 301  response status reference.</p> <p>For this to work, you must update the old domain's DNS record to point to the new instance's IP,  otherwise you won't be able to obtain the certificates.</p> <p>First, declare these variables in the <code>local.env</code> file:</p> <pre><code>BENTO_DOMAIN_REDIRECT=old-bento.example.com     # The old domain name\nBENTO_USE_DOMAIN_REDIRECT='true'                # Feature flag for domain redirect\nBENTO_GATEWAY_INTERNAL_REDIRECT_FULLCHAIN_RELATIVE_PATH=/live/$BENTO_DOMAIN_REDIRECT/fullchain.pem\nBENTO_GATEWAY_INTERNAL_REDIRECT_PRIVKEY_RELATIVE_PATH=/live/$BENTO_DOMAIN_REDIRECT/privkey.pem\n</code></pre> <p>Obtain the certificate for the old domain with certbot:</p> <pre><code># Stop gateway\n./bentoctl.bash stop gateway\n\n# Obtain certificates\ndocker run -it --rm --name certbot \\\n    -v \"./certs/gateway/letsencrypt:/etc/letsencrypt\" \\\n    -v \"./certs/gateway/letsencrypt/lib:/var/lib/letsencrypt\" \\\n    -p 80:80 -p 443:443 \\\n    certbot/certbot certonly -d old-bento.example.com -d portal.old-bento.example.com\n\n# Subdomains are optional but recommended, add the ones you want redirected with the '-d' flag\n# This creates a single certificate, even if using multiple subdomains.\nls certs/gateway/letsencrypt/live/\n\n# Start the gateway\n./bentoctl.bash run gateway\n</code></pre> <p>If all went well, the <code>old-bento.example.com</code> domain should be redirected to <code>bento.example.com</code> in a browser.</p>"},{"location":"deployment/#discovery-configuration","title":"Discovery configuration","text":"<p>Bento can serve censored data publicly if configured to do so. This allows anonymous users to take a glimpse into the data hosted by a Bento node.</p> <p>When deploying a Bento instance, make sure that the discovery settings are configured properly at the necessary levels. Consult the public discovery documentation for more details.</p>"},{"location":"dev-container/","title":"Using Bento with Dev-containers in VS Code","text":"<p>When a development container is running, the local repository containing the application code is mounted as a local volume within the container. It's possible to attach a VS Code instance to the running container so that the IDE has directly access to the environment within the container. The advantages are: - The VS Code terminal is the container local shell - The python interpreter used by VS Code is the one running in the container - The python modules are resolved based on the modules installed within the container - A debugger can be attached</p>"},{"location":"dev-container/#prerequisites","title":"Prerequisites","text":""},{"location":"dev-container/#vs-code-extensions","title":"VS Code extensions","text":"<p>The following extension is required for enabling remote development - Remote - Containers</p> <p>The following extension is helpful for managing Docker containers - Docker</p>"},{"location":"dev-container/#attach-vs-code-to-a-running-container","title":"Attach VS Code to a running container","text":"<ul> <li>Build the container in dev mode. This is necessary to have the local workspace For example:</li> </ul> <pre><code>make stop-katsu\nmake clean-katsu\nmake run-katsu-dev\n</code></pre> <p>Other services available are drs and wes</p> <ul> <li>In VS Code, with the workspace opened, click on the Remote Quick Access button in the status bar, and select \"Attach to Running Container\" from the drop-down menu. This will install the VS Code server in the container after a few minutes. VS Code will detect that the project is python based and will install extensions for python development. This will require reloading the window once all the installation steps have been completed.</li> </ul> <p></p>"},{"location":"dev-container/#using-the-debugger","title":"Using the debugger","text":"<p>Debugging is done using the debugpy module. For it to work, it must be installed in the container (usually via the Dockerfile) and invoked when running the application.</p> <pre><code># Dockerfile\nRUN pip install debugpy -r requirements.txt;\n</code></pre> <pre><code># Docker compose (note the threads parameter is set to 1)\nentrypoint:\n      - (...) gunicorn chord_metadata_service.metadata.wsgi:application -w 1 --threads 1 -b 0.0.0.0:8080\n</code></pre> <pre><code># For example in Django wsgi.py\nimport debugpy\ndebugpy.listen((\"0.0.0.0\", 5678))\n</code></pre>"},{"location":"dev-container/#vs-code-configuration","title":"VS Code configuration","text":"<p>The port configuration for the debugger is passed using the file <code>launch.json</code> located in the <code>.vscode/</code> folder of the workspace.</p> <pre><code>{\n  \"version\": \"0.2.0\",\n  \"configurations\": [\n    {\n      \"name\": \"Python: Attach Debugger\",\n      \"type\": \"debugpy\",\n      \"request\": \"attach\",\n      \"listen\": {\n          \"host\": \"0.0.0.0\",\n          \"port\": 5678\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"dev-container/#debugging-in-vs-code","title":"Debugging in VS Code","text":"<p>Add a breakpoint in the code to debug. Click on the debugger button, and choose \"Python: Attach Debugger\" in the drop-down menu. Once the debugger is attached (status is displayed in the Debug Console), launch a request. The execution should stop at breakpoint where the current stack environment may be explored (variables content, execution stack, etc...)</p>"},{"location":"development/","title":"Development","text":"<p>Before running any installation steps, make sure you've  set up <code>bentoctl</code> and have activated its virtual environment.</p>"},{"location":"development/#accessing-containers-with-bentoctl","title":"Accessing containers with <code>bentoctl</code>","text":"<p>To start a shell session within a particular container, use the following command (here, <code>web</code> is used as an example):</p> <pre><code>./bentoctl.bash shell web\n</code></pre> <p>Optionally, the shell to run can be specified via <code>--shell /bin/bash</code> or <code>--shell /bin/sh</code>.</p>"},{"location":"development/#working-on-web-as-an-example","title":"Working on <code>web</code> (as an example)","text":"<p>To work on the <code>bento_web</code> repository within a BentoV2 environment, run the following command:</p> <pre><code>./bentoctl.bash work-on web\n</code></pre> <p>This will clone the <code>bento_web</code> repository into <code>./repos/web</code> if necessary, pull the local  development image, and start it in local mode. In this mode, the container has a volume mapping to the <code>./repos/web</code> directory, which means on-the-fly Webpack building will be available. </p> <p>All local-mode services are inherently in development mode, even if <code>MODE=prod</code> globally,  through inheritance of Compose files.</p> <p>You can find the default image tag variables in <code>./etc/bento.env</code> and overwrite them in <code>local.env</code>, look for the  pattern <code>BENTOV2_[name]_VERSION</code>. </p> <p>The version tags correspond to the PR number (not its name), e.g. <code>BENTOV2_WEB_VERSION=pr-216</code> indicates that the  image was built from PR #216 in bento_web. </p> <p>Note: Most of the time, you will not need to worry about changing this,  unless changes were made to the dev image's entrypoint.</p>"},{"location":"development/#where-are-the-docker-images","title":"Where are the Docker images?","text":"<p>By default, the images used are those built by GitHub CI workflows, triggered by commit and PR events and published  to the Bento images registry. If after changing the version tag of  an image the service's container can no longer be created, it is probably because the tag does not exist on GitHub.</p> <p>To remediate this, you have two options: - Create a PR for the branch you want to work on, in order to trigger a CI workflow that will build an image tagged    with the PR number (prefered) - Manually build and tag a docker image on your machine (avoid when possible)</p>"},{"location":"development/#local-bento_web-image-example","title":"Local <code>bento_web</code> image example","text":"<p>Note: this approach is a last resort for local development only. In some situations, we cannot always assume that  working CI artifacts are available for every service used by Bento.</p> <p>For the example, lets assume we changed <code>BENTOV2_WEB_VERSION</code> to be equal to <code>localonly</code>, which automatically  makes <code>BENTOV2_WEB_VERSION_DEV=localonly-dev</code>.</p> <pre><code># Switch web to local mode\nbentoctl work-on web\n\n# Move to cloned local service directory\ncd ./repos/web\n\n# Checkout to a specific branch, or create a new one\ngit checkout [...]\n\n# Build the dev.Dockerfile on your machine, using the env variables values\n# Tag 1 =&gt; BENTOV2_WEB_IMAGE:BENTOV2_WEB_VERSION\n# Tag 2 =&gt; BENTOV2_WEB_IMAGE:BENTOV2_WEB_VERSION_DEV\ndocker build -f dev.Dockerfile . \\\n  -t ghcr.io/bento-platform/bento_web:localonly \\\n  -t ghcr.io/bento-platform/bento_web:localonly-dev\n\n# Back to root\ncd ../../\n\n# Start web with your local image\n./bentoctl.bash run web\n</code></pre> <p>\u26a0\ufe0f Warning for local development \u26a0\ufe0f</p> <p>In local mode, be sure to navigate to the cloned repository <code>./repos/web/</code> (or any other service repo you want to work  on locally), and checkout on the PR branch from which the dev Docker image was built. </p>"},{"location":"development/#migrating-the-repository-from-v210-and-prior","title":"Migrating the repository from v2.10 and prior","text":"<p>Move your local <code>bento_web</code> project to the <code>./repos</code> directory (named <code>web</code>):</p> <pre><code>mv ./path/to/my/bentoweb ./repos/web\n</code></pre> <p>You will then have <code>repos/web</code> available for the <code>./bentoctl.bash work-on web</code> command, which will spin up the  <code>web</code> container tethered to your local directory with a Docker volume. Internally,  <code>npm run watch</code> is executed so changes made locally will be reflected in the container.</p> <p>Note: if you get stuck on an NGINX <code>500 Internal Service Error</code>, give it another minute to spin up. If it persists,  run <code>./bentoctl.bash shell web</code> to access the container, and then run <code>npm run watch</code> manually.</p>"},{"location":"development/#switching-web-back-to-a-pre-built-version","title":"Switching <code>web</code> back to a pre-built version","text":"<p>In the section above, we switched <code>web</code> to a local version where the code is attached to the container via a Docker bind mount (i.e., a filesystem path volume). To switch back to a pre-built version of <code>web</code>, run the following command:</p> <pre><code>./bentoctl.bash prebuilt web\n</code></pre> <p>This will work for any service where both a local development and pre-built image exist.</p>"},{"location":"development/#communicating-with-services-in-development","title":"Communicating with services (in development)","text":"<p>When <code>MODE=dev</code>, some service containers are bound to ports on the host, so debugging can be done without going through the gateway.</p> <p>The following is a list of all host port allocations for Bento services in development mode:</p> Service Port Debugger Port Adminer 8080 <code>N/A</code> Aggregation 9500 5684 Beacon 5000 5683 cBioPortal 8089 <code>N/A</code> Drop Box 6000 Unimplemented DRS 7007 5682 Elasticvue 8081 <code>N/A</code> Event relay 8750 Unimplemented Katsu 8000 5678 Katsu DB 5432 <code>N/A</code> Notification 8500 5681 Public 8090 Unimplemented Redis 6379 <code>N/A</code> Reference 9510 9501 Reference DB 9512 <code>N/A</code> Service Registry 5010 Unimplemented WES 9250 5680"},{"location":"development/#local-npm-package-development","title":"Local NPM package development","text":"<p>The bento_web and  bento_public projects use Bento specific packages for  charts and  auth.</p> <p>In production, these packages are installed from the NPM registry. When developing simultanuously on a given web app and package,  it is helpful to be able to use the locally built package without  having to publish unfinished dev packages to NPM.</p> <p>For this use case:</p> <pre><code># cd to the package's code directory\ncd ../bento_charts # assumes bento_charts is in parent dir\n\n# Build and pack the package as a .tgz file\nnpm run buildpack\n\n# Go back to Bento's dir\ncd ../bento\n\n# Copy the packaged file to the Bento packs dir\ncp ../bento_charts/packs/*.tgz ./packs\n\n# Start a web app in dev mode\nbentoctl dev web\n\n# Open a shell in the container (or open the dev container with Code)\nbentoctl shell web\n\n# Install the package using the mounted pack file on /packs\nnpm install /packs/bento-charts-2.5.0.tgz\n</code></pre> <p>If subsequent modifications are made to the package's code, you will need to create a new pack file  and install it again in the app with <code>npm install</code>.</p>"},{"location":"development/#adding-services","title":"Adding services","text":"<p>See <code>adding-services.md</code> for some considerations when adding new services to Bento.</p>"},{"location":"development/#using-adminer","title":"Using Adminer","text":"<p>An Adminer container is deployed in dev and local mode, it can be used to inspect the Katsu database during development.</p> <p>Go to <code>localhost:8080</code> to access the login page. Fill the fields with the values shown below, using the value of <code>BENTOV2_KATSU_DB_PASSWORD</code> for the password field.</p> <p></p>"},{"location":"development/#using-elasticvue","title":"Using Elasticvue","text":"<p>An Elasticvue container is also deployed in dev and local mode,  allowing users to inspect the Gohan Elasticsearch node in a GUI.</p> <p>Go to <code>localhost:8081</code> to access the Elasticvue interface. Fill the username field with <code>elastic</code> and the password  field with the value of <code>BENTOV2_GOHAN_ES_PASSWORD</code>. The Uri field must use the IP of the gohan-es container on  port 9200 (e.g. http://192.168.48.2:9200), it can be found with this command: <code>docker inspect bentov2-gohan-elasticsearch | grep -i ipaddress</code></p> <p>Note: the CORS instructions have already been taken care of in the <code>docker-compose.dev.yaml</code> file.</p> <p></p>"},{"location":"development/#converting-phenopackets","title":"Converting Phenopackets","text":"<p>Phenopackets JSON documents can be converted from V1  to V2 using <code>bentoctl</code> and  Phenopacket-tools as its backend.</p> <p>See the relevant guide: Converting Phenopackets from V1 to V2 using <code>bentoctl</code></p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#1-set-up-bentoctl","title":"1. Set up <code>bentoctl</code>","text":"<p>See the following guide: <code>bentoctl</code>: the Bento deployment command line management tool</p> <p>Before running any installation steps, make sure you've set up <code>bentoctl</code> and have activated its virtual environment.</p>"},{"location":"installation/#2-provision-configuration-files","title":"2. Provision configuration files","text":""},{"location":"installation/#instance-specific-environment-variable-file-localenv","title":"Instance-specific environment variable file: <code>local.env</code>","text":"<p>Depending on your use, development or deployment, you will need to copy the right template file to <code>local.env</code> in the root of the <code>bento</code> folder, i.e., the repository folder:</p> <pre><code># Dev\ncp ./etc/bento_dev.env local.env\n\n# Deployment\ncp ./etc/bento_deploy.env local.env\n</code></pre> <p>Then, modify the values as needed; depending on if you're using the instance for development or deployment.</p>"},{"location":"installation/#development-example","title":"Development example","text":"<p>For an example of a semi-completed development configuration, see <code>etc/bento_dev.env</code>. In the step above, this file was copied to <code>local.env</code>, and you must now edit <code>local.env</code> to specify secrets and other deployment-specific values.</p> <p>You should at least fill to the following settings in dev mode (it may differ for a production setup), which are not set in the example file:</p> <ul> <li><code>BENTOV2_SESSION_SECRET</code></li> <li><code>BENTO_AUTH_DB_PASSWORD</code></li> <li><code>BENTO_AUTHZ_DB_PASSWORD</code></li> <li><code>BENTO_AGGREGATION_CLIENT_SECRET</code></li> <li><code>BENTO_WES_CLIENT_SECRET</code></li> </ul> <p>If the internal OIDC identity provider (IdP) is being used (by default, Keycloak), variables specifying default credentials should also be provided. The admin credentials are used to connect to the Keycloak UI for authentication management (adding users, getting client credentials, ...). The test credentials will be used to authenticate on the Bento Portal.</p> <pre><code>BENTOV2_AUTH_ADMIN_USER=testadmin\nBENTOV2_AUTH_ADMIN_PASSWORD=testpassword123\n\nBENTOV2_AUTH_TEST_USER=testuser\nBENTOV2_AUTH_TEST_PASSWORD=testpassword123\n</code></pre> <p>If using an external identity provider, adjust the following auth variables according to the external IdP's specifications:</p> <pre><code>BENTOV2_AUTH_CLIENT_ID=local_bentov2\nBENTOV2_AUTH_REALM=bentov2\n\nBENTOV2_AUTH_WELLKNOWN_PATH=/auth/realms/${BENTOV2_AUTH_REALM}/.well-known/openid-configuration\n</code></pre> <p>If an external Keycloak instance is being used and you would like to set it up using <code>./bentoctl.bash init-auth</code>, follow the steps above for external IdPs and then below:</p> <ul> <li>Set up a keycloak instance and provide its URL in <code>BENTOV2_AUTH_PUBLIC_URL</code></li> <li>Make the desired Bento realm and update <code>BENTOV2_AUTH_REALM</code> accordingly</li> <li>Create an administrative user account in the Bento realm</li> <li>In Realm Roles, create an admin role, which we will give to the administrative user later</li> <li>In the admin role, go to the associated roles tab and assign all the realm-management roles to the admin realm role.</li> <li>In the admin user page, select the Role Mapping tab and click on the Assign Role button</li> <li>Select Filter By Realm Roles, select the admin role and click Assign</li> <li>The user account can then be used to remotely configure the realm with the admin API</li> <li>Set the credential variables in <code>local.env</code></li> <li>To provide credentials during <code>init-auth</code> (recommended)<ul> <li><code>BENTOV2_AUTH_ADMIN_USER=''</code> &amp; <code>BENTOV2_AUTH_ADMIN_PASSWORD=''</code></li> <li>You will then be prompted to provide the credentials</li> </ul> </li> <li>To store the credentials in an environment variable<ul> <li><code>BENTOV2_AUTH_ADMIN_USER=&lt;admin username&gt;</code> &amp; <code>BENTOV2_AUTH_ADMIN_PASSWORD=&lt;admin password&gt;</code></li> </ul> </li> <li>Set <code>BENTOV2_USE_EXTERNAL_KEYCLOAK=1</code> in <code>local.env</code></li> <li>Run <code>./bentoctl.bash init-auth</code></li> </ul> <p>This administrative user account should only be used to configure a Keycloak realm for a Bento instance. As such, once your Bento instance is properly configured with your remote Keycloak, we recommend that you unassign the admin realm role from the admin user and reset credentials. Doing so mitigates the potential security risks caused by leaked admin credentials.</p> <p>If you need to re-run <code>bentoctl init-auth</code> later, you can set new credentials and reassign the admin role for the configuration process.</p> <p><code>bentoctl init-auth</code> would skip test user creation. Test users can be created using the admin console for the external keycloak.</p>"},{"location":"installation/#bento-public-configuration","title":"Bento Public configuration","text":"<p>Then, copy the <code>bento_public</code> configuration file to its correct location for use by Katsu, Bento's clinical/phenotypic metadata service:</p> <pre><code># public service configuration file. Required if BENTOV2_USE_BENTO_PUBLIC flag is set to `1`\n# See Katsu documentation for more information about the specifications\n./bentoctl.bash init-config katsu\n</code></pre>"},{"location":"installation/#beacon-configuration","title":"Beacon configuration","text":"<p>If using Beacon, first copy the configuration file:</p> <pre><code>./bentoctl.bash init-config beacon\n</code></pre> <p>Then update any config values as needed at <code>lib/beacon/config/beacon_config.json</code> and <code>lib/beacon/config/beacon_cohort.json</code>.</p> <p>If using the Beacon network, copy the configuration file:</p> <pre><code>./bentoctl.bash init-config beacon-network\n</code></pre> <p>and update values at <code>lib/beacon/config/beacon_network_config.json</code>.</p>"},{"location":"installation/#gohan-configuration","title":"Gohan configuration","text":""},{"location":"installation/#production","title":"Production","text":"<p>When deploying a Bento node that needs to serve variants data, it is recommended to allot larger portions of your compute resources to both <code>bentov2-gohan-api</code> and <code>bentov2-gohan-elasticsearch</code>. Since variants are stored in memory in Elasticsearch, set the <code>BENTOV2_GOHAN_ES_MEM_LIM</code> variable to an appropriate value.</p> <p>Alloting additional CPUs with <code>BENTOV2_GOHAN_API_CPUS</code> and <code>BENTOV2_GOHAN_ES_CPUS</code> will result in shorter ingestion times. Consider this option if you need to ingest a large number of VCFs.</p> <p>Go through the official Elasticsearch checklist for production deployments on Docker.</p> <p>The following configurations MUST be applied to the host machine deploying the Elasticsearch container:</p> <ul> <li>Set <code>vm.max_map_count</code></li> <li>Disable swapping</li> </ul>"},{"location":"installation/#elasticsearch-jvm-options","title":"Elasticsearch JVM options","text":"<p>In production, using the default JVM options provided by Elasticsearch is recommended.</p> <p>In development, modifying the JVM heap size could be needed if Elasticsearch's memory limit is low and you are trying to ingest VCFs. The heap size can be modified by providing a config file to the <code>bentov2_gohan-elasticsearch</code> container:</p> <pre><code>cp ./etc/default.gohan.es.jvm.options ./lib/gohan/es_jvm_options/jvm.options\n</code></pre> <p>Set <code>Xms</code> and <code>Xmx</code> to no more than 50% of the <code>BENTOV2_GOHAN_ES_MEM_LIM</code> value. For more details, check the official Elasticsearch doc on heap size.</p>"},{"location":"installation/#3-development-only-create-self-signed-tls-certificates","title":"3. Development only: create self-signed TLS certificates","text":"<p>First, set up your local Bento and Keycloak hostnames (something like <code>bentov2.local</code>, <code>portal.bentov2.local</code>, and <code>bentov2auth.local</code>) in the <code>.env</code> file. You can then create the corresponding TLS certificates for local development.</p> <p>Setting up the certificates with <code>bentoctl</code> can be done in a single command. From the project root, run</p> <pre><code>./bentoctl.bash init-certs\n</code></pre> <p>NOTE: This command will skip all certificate generation if it detects previously created files. To force an override, simply add the option <code>--force</code> / <code>-f</code>.</p> <p>After creating the three certificates, it is worth ensuring your browser has security exceptions for these certificates and domains. Navigate to each of the three domains mentioned above and add security exceptions to ensure cross-origin requests will occur correctly.</p>"},{"location":"installation/#4-development-only-hosts-file-configuration","title":"4. Development only: Hosts file configuration","text":"<p>Ensure that the local domain names are set in the machines <code>hosts</code> file (for Linux users, this is likely <code>/etc/hosts</code>, and in Windows, <code>C:\\Windows\\System32\\drivers\\etc\\hosts</code>) pointing to either <code>localhost</code>, <code>127.0.0.1</code>, or <code>0.0.0.0</code>, depending on whichever gets the job done on your system.</p> <p>With the default development configuration, this might look something like:</p> <pre><code># ... system stuff above\n127.0.0.1   bentov2.local\n127.0.0.1   portal.bentov2.local\n127.0.0.1   bentov2auth.local\n# ... other stuff below\n</code></pre> <p>If you are working with cBioPortal, you will need another line:</p> <pre><code># ...\n127.0.0.1   cbioportal.bentov2.local\n# ...\n</code></pre> <p>Editing <code>/etc/hosts</code> is not needed in production, since the domains should have DNS records.</p> <p>Make sure these values match the values in the <code>.env</code> file and what was issued in the self-signed certificates, as specified in the step above.</p>"},{"location":"installation/#5-initialize-and-boot-the-gateway","title":"5. Initialize and boot the gateway","text":"<p>NOTE: <code>./bentoctl.bash</code> commands seen here aren't the only tools for operating this cluster. Run <code>./bentoctl.bash --help</code> for further documentation.</p> <pre><code># Once the certificates are ready, initialize various aspects of the cluster:\n./bentoctl.bash init-all\n# Which is equivalent to:\n\n#   # Once the certificates are ready, initialize the cluster configs secrets\n#   ./bentoctl.bash init-dirs\n#   ./bentoctl.bash init-docker\n#   ./bentoctl.bash init-secrets\n#\n#   # Initialize bento_web and bento_public\n#   ./bentoctl.bash init-web private\n#   ./bentoctl.bash init-web public\n\n# If you are running the bentoV2 with the use of an internal identity provider (defaults to Keycloak),\n# i.e setting BENTOV2_USE_EXTERNAL_IDP=0, run both\n./bentoctl.bash run auth\n./bentoctl.bash run gateway\n# and\n./bentoctl.bash init-auth\n</code></pre> <p>After running <code>init-auth</code>, be sure to put all client secrets into your <code>local.env</code> file!</p> <p>If using an external identity provider, only start the cluster's gateway after setting various <code>*_CLIENT_SECRET</code> variables in your local environment file:</p> <pre><code>./bentoctl.bash run gateway\n</code></pre>"},{"location":"installation/#note-on-keycloak","title":"Note on Keycloak","text":"<p>This last step boots and configures the local OIDC provider (Keycloak) container and reconfigures the gateway to utilize new variables generated during the OIDC configuration.</p> <p>NOTE: by default, the <code>gateway</code> service does need to be running for this to work as the configuration will pass via the URL set in the <code>.env</code> file which points to the gateway.</p> <p>If you do not plan to use the built-in OIDC provider, you will have to handle auth configuration manually.</p>"},{"location":"installation/#6-configure-permissions","title":"6. Configure permissions","text":""},{"location":"installation/#a-create-superuser-permissions-in-the-bento-authorization-service","title":"a. Create superuser permissions in the Bento authorization service","text":"<p>First, run the authorization service and then open a shell into the container:</p> <pre><code>./bentoctl.bash run authz\n./bentoctl.bash shell authz\n</code></pre> <p>Then, run the following command for each user ID you wish to assign superuser permissions to:</p> <pre><code>bento_authz assign-all-to-user iss sub\n</code></pre> <p>Where <code>iss</code> is the issuer (for example, <code>https://bentov2auth.local/realms/bentov2</code>) and <code>sub</code> is the user (subject) ID, which in Keycloak should be a UUID.</p>"},{"location":"installation/#b-create-grants-for-the-workflow-execution-service-wes-oauth2-client","title":"b. Create grants for the Workflow Execution Service (WES) OAuth2 client","text":"<p>Run the following commands to set up authorization for the WES client. Don't forget to replace <code>&lt;ISSUER_HERE&gt;</code> with the issuer URL!</p> <pre><code># This grant is a temporary hack to get permissions working for v12/v13. In the future, it should be removed.\nbento_authz create grant \\\n  '{\"iss\": \"&lt;ISSUER_HERE&gt;\", \"client\": \"wes\"}' \\\n  '{\"everything\": true}' \\\n  'view:private_portal'\n\n# This grant gives permission to access and ingest data into all projects and the reference genome service\nbento_authz create grant \\\n  '{\"iss\": \"&lt;ISSUER_HERE&gt;\", \"client\": \"wes\"}' \\\n  '{\"everything\": true}' \\\n  'query:data' 'ingest:data' 'ingest:reference_material' 'delete:reference_material'\n</code></pre>"},{"location":"installation/#c-create-a-grant-for-the-aggregation-and-beacon-services","title":"c. Create a grant for the aggregation and Beacon services","text":"<p>Run the following commands to set up authorization for the aggregation/Beacon client. Don't forget to replace <code>&lt;ISSUER_HERE&gt;</code> with the issuer URL!</p> <pre><code># In the future, view:private_portal will need to be removed from this grant.\nbento_authz create grant \\\n  '{\"iss\": \"&lt;ISSUER_HERE&gt;\", \"client\": \"aggregation\"}' \\\n  '{\"everything\": true}' \\\n  'query:data' 'view:private_portal'\n</code></pre>"},{"location":"installation/#d-configure-public-data-access-for-all-users-including-anonymous-visitors-if-desired","title":"d. Configure public data access for all users, including anonymous visitors (if desired):","text":"<p>To configure public data access, run the following command in the authorization service container. Note that with the <code>full</code> value, THIS GIVES FULL DATA ACCESS TO EVERYONE WHO VISITS YOUR INSTANCE!</p> <pre><code># Configure public data access\n# ----------------------------\n# The level below (\"counts\") preserves previous functionality. Other possible options are:\n#  - none - will do nothing.\n#  - bool - for censored true/false discovery, but in effect right now forbids access.\n#  - counts - for censored count discovery.\n#  - full - allows full data access (record-level, including sensitive data such as IDs), uncensored counts, etc.\nbento_authz public-data-access counts\n</code></pre>"},{"location":"installation/#e-assign-portal-access-to-all-users-in-the-instance-realm","title":"e. Assign portal access to all users in the instance realm","text":"<p>We added a special permission, <code>view:private_portal</code>, to Bento v12/v13 in order to carry forward the current 'legacy' authorization behaviour for one more major version. This permission currently behaves as a super-permission, allowing all actions within the private portal. However, in the future, this permission will do almost nothing.</p> <p>To carry forward legacy behaviour of all users in the instance realm being able to do everything, run the following command in the authorization service container:</p> <pre><code># Create the grant\nbento_authz create grant \\\n  '{\"iss\": \"ISSUER_HERE\", \"client\": \"WEB_CLIENT_ID_HERE\"}' \\\n  '{\"everything\": true}' \\\n  'view:private_portal'\n</code></pre> <p>Where <code>WEB_CLIENT_ID_HERE</code> is the OAuth2 client the web portal uses, i.e., the value in the <code>BENTOV2_AUTH_CLIENT_ID</code> environment variable. On local instances, this is set to <code>local_bentov2</code> by default.</p>"},{"location":"installation/#7-production-only-set-up-translations-and-branding","title":"7. Production only: set up translations and branding","text":"<p>Now that Bento Public and Web have been initialized by either <code>./bentoctl.bash init-all</code> or <code>./bentoctl.bash init-web &lt;public|web&gt;</code>, translation files and branding (logos) can be configured as necessary.</p> <p>For branding (logos), copy files to the following paths:</p> <ul> <li>A logo which works on dark backgrounds should be placed at <code>lib/public/branding.png</code> and <code>lib/web/branding.png</code>.</li> <li>A logo which works on light backgrounds should be placed at <code>lib/public/branding.lightbg.png</code>. This is primarily   useful for Beacon Network.</li> </ul> <p>For translations (which apply only to Bento Public), adjust the default translation set as necessary:</p> <pre><code>// lib/public/translations/&lt;en|fr&gt;.json\n\n{\n  \"Age\": \"Age\",\n  \"Sex\": \"Sex\",\n  \"Verbal consent date\": \"Verbal Consent Date\",\n  \"Functional status\": \"Functional Status\",\n  \"Lab Test Result\": \"Lab Test Results\",\n  \"Experiment Types\": \"Experiment Types\",\n  \"Demographics\": \"Demographics\",\n  \"MALE\": \"MALE\",\n  \"FEMALE\": \"FEMALE\",\n  \"I have no problems in walking about\": \"I have no problems in walking about\",\n  \"Results\": \"Results\"\n}\n\n\n{\n  \"MALE\": \"HOMME\",\n  \"FEMALE\": \"FEMME\",\n  \"Age\": \"\u00c2ge\",\n  \"Sex\": \"Sexe\",\n  \"Demographics\": \"D\u00e9mographie\",\n  \"Verbal consent date\": \"Date de consentement verbal\",\n  \"Functional status\": \"Statut fonctionnel\",\n  \"Lab Test Result\": \"R\u00e9sultats des tests de laboratoire\",\n  \"Experiment Types\": \"Types d'exp\u00e9riences\",\n  \"I have no problems in walking about\": \"Je n\u2019ai aucun probl\u00e8me \u00e0 marcher\",\n  \"Results\": \"R\u00e9sultats\"\n}\n</code></pre>"},{"location":"installation/#8-start-the-cluster","title":"8. Start the cluster","text":"<pre><code>./bentoctl.bash run all\n# or\n./bentoctl.bash run\n# (these are synonymous)\n</code></pre> <p>to run all Bento services.</p>"},{"location":"installation/#stopping-and-cleaning-the-cluster","title":"Stopping and cleaning the cluster","text":"<p>Run</p> <pre><code>./bentoctl.bash stop all\n</code></pre> <p>to shut down the whole cluster.</p> <p>To remove the Docker containers, run the following:</p> <pre><code>./bentoctl.bash clean all\n</code></pre> <p>NOTE: application data does persist after cleaning (depending on data path, e.g., <code>./data/[auth, drs, katsu]/...</code> directories)</p>"},{"location":"installation/#9-ingest-reference-material","title":"9. Ingest reference material","text":"<p>To support genomic data and gene querying, a reference genome (FASTA) and GFF3 gene catalog must be ingested. Follow these steps:</p> <ol> <li>Download your reference genome and GFF3 gene catalog files from RefSeq or a similar database.</li> <li>Upload these files to your Bento instance's drop box.</li> <li>Have a Phenopackets JSON-style ontology term (from the    <code>NCBITaxon</code> ontology) ready, e.g.:    <code>json    { \"id\": \"NCBITaxon:9606\", \"label\": \"Homo sapiens\" }</code></li> <li>Navigate to <code>/data/manager/ingestion</code> in the Bento private portal and ingest the reference FASTA and GFF3 into the    reference service. This will take some time.</li> </ol>"},{"location":"installation/#set-up-gohans-gene-catalogue-legacy-instructions","title":"Set Up Gohan's Gene Catalogue (Legacy instructions)","text":"<p>To enable gene querying support in versions of Bento before v16, follow these steps to set up Gohan's gene catalogue:</p> <ol> <li> <p>Access the Services Portal:</p> </li> <li> <p>Navigate to the <code>Services</code> tab on the portal.</p> </li> <li> <p>Initiate Gohan Request:</p> </li> <li> <p>Click the <code>Make Request</code> button for Gohan.</p> </li> <li> <p>Edit and Trigger Ingestion Endpoint:</p> </li> <li> <p>Modify the endpoint to <code>genes/ingestion/run</code>.</p> </li> <li> <p>Click <code>Get</code> to initiate Gohan's download and processing of the default GenCode <code>.gtk</code> files from the internet.</p> </li> <li> <p>Monitor the Ingestion Process:</p> </li> <li> <p>Use the endpoint <code>genes/ingestion/requests</code> to track the progress of the ingestion process.</p> </li> <li> <p>Access the Gene Catalogue:</p> </li> <li>Once the ingestion process is complete, the gene catalogue will be available at <code>genes/overview</code>.</li> </ol>"},{"location":"json-schemas/","title":"JSON Schemas for data types and discovery configuration","text":"<p>Bento's services perform some of the data validation using JSON Schemas.</p> <p>For a given version, Bento's services expect data to respect the schemas in use for: - Phenopackets - Experiments - Discovery configuration</p> <p>Starting with Bento v17 (Katsu v9.0.0),  the compiled JSON Schemas are published as Katsu release artifacts.</p> Bento Release JSON Schemas Download v17 Katsu v9.0.0 json-schemas.zip"},{"location":"minio/","title":"Bento MinIO","text":"<p>Bento can be deployed with a MinIO service. The MinIO service provides an S3 compatible API  for object storage.</p> <p>It is mostly intended for development and testing purposes with the S3 API,  as we are working on enabling S3 storage for Bento.</p> <p>For deployments, Bento instances requiring large storage capacity should rely on an external managed  S3 storage provider (AWS, Ceph, production MinIO cluster, etc).  This will allow Bento deployments to be decoupled from disk storage concerns.</p>"},{"location":"minio/#routing","title":"Routing","text":"<p>Note: As shown above, the MinIO service relies on disk storage, which is why production environments should consider external S3 storage instead.</p>"},{"location":"minio/#configuration","title":"Configuration","text":"<p>To enable the MinIO service in a Bento deployment, please follow the instructions bellow.</p>"},{"location":"minio/#environment-variables","title":"Environment variables","text":"<p>Enable MinIO by setting the feature flag and other required variables in <code>local.env</code>.</p> <pre><code>BENTO_MINIO_ENABLED='true'\nBENTO_MINIO_ROOT_USER=root                  # default value, can be changed\nBENTO_MINIO_ROOT_PASSWORD=secure-password   # change to a secure pw\nBENTO_MINIO_DOMAIN=minio.${BENTOV2_DOMAIN}  # MUST be a subdomain of BENTOV2_DOMAIN\n</code></pre>"},{"location":"minio/#domain-resolution","title":"Domain resolution","text":"<p>In a VM using a trusted certificate authority, there should be a DNS record for <code>BENTO_MINIO_DOMAIN</code>.</p> <p>In a local development environment, you must specify how <code>BENTO_MINIO_DOMAIN</code> should be resolved,  simulating a DNS record for self-signed certificates.</p> <p>Assuming <code>BENTO_MINIO_DOMAIN=minio.bentov2.local</code>, add the following line to your <code>/etc/hosts</code> file:</p> <pre><code># /etc/hosts\n127.0.0.1       minio.bentov2.local\n</code></pre>"},{"location":"minio/#initialize-minio-certificates-networking-and-directories","title":"Initialize MinIO certificates, networking and directories","text":"<p>After enabling the MinIO feature flag for the first time and setting domain resolution,  you must initialize the Docker networks, mounted directories and certs.</p> <pre><code>./bentoctl.bash init-certs -f   # creates the self-signed certificate for MinIO\n./bentoctl.bash init-docker     # creates the Docker network for MinIO\n./bentoctl.bash init-dirs       # creates MinIO's data directory to be mounted\n</code></pre>"},{"location":"minio/#start-minio","title":"Start MinIO","text":"<p>If all previous steps were performed correctly, you are ready to restart the  gateway and start the MinIO service!</p> <pre><code># Will recreate the gateway container automatically and start MinIO.\n./bentoctl.bash run\n</code></pre>"},{"location":"minio/#using-the-console","title":"Using the console","text":"<p>The console can be accessed using a web browser, simply navigate to minio.bentov2.local/minio/ui/.</p> <p>Authenticate using <code>BENTO_MINIO_ROOT_USER</code> and <code>BENTO_MINIO_ROOT_PASSWORD</code>.</p> <p>Once logged in, you can issue access keys. These keys can be used to make  S3 API calls.</p>"},{"location":"minio/#using-minios-s3-api","title":"Using MinIO's S3 API","text":"<p>Assuming you created an access key in the console and saved the values,  you are ready to make object storage operations through the S3 API.</p> <p>Interactions between clients and the S3 API all take place over HTTP. Many CLI tools and libraries are available to simplify these operations.</p>"},{"location":"minio/#s3cmd","title":"S3cmd","text":"<p>S3cmd is a popular CLI tool to interact with object stores that support the S3 protocol, including MinIO.</p> <p>Once S3cmd is installed on a machine, you can create a s3cmd configuration file for the S3 API endpoint of your choice.</p> <pre><code># ~/.s3cfg-minio-local\nhost_base = minio.bentov2.local     # S3 API endpoint (local here)\nhost_bucket = minio.bentov2.local   \nuse_https = True                    # Use HTTPS\n\n# For dev self-signed certs only\ncheck_ssl_certificate = False       # Enable if using trusted CA\n\n# Setup access keys\naccess_key = &lt;OBTAIN FROM MINIO CONSOLE&gt;\nsecret_key = &lt;OBTAIN FROM MINIO CONSOLE&gt;\n</code></pre> <p>With the S3cmd config file in place, you can start creating buckets, uploading files, and much more.</p> <pre><code># list buckets (empty at first)\ns3cmd -c ~/.s3cfg-minio-local ls\n\n# Create a bucket named 'test'\ns3cmd -c ~/.s3cfg-minio-local mb s3://test\n\n# Upload a file to your new bucket!\ns3cmd -c ~/.s3cfg-minio-local put some-file.txt s3://test/some-file.txt\n</code></pre>"},{"location":"minio/#boto3","title":"Boto3","text":"<p>Boto3  is an official AWS Python package to interact with an S3 compatible object store.</p> <p>Like S3cmd, it must be configured to use access keys.</p> <p>Future work on DRS and Drop-Box will involve Boto3 to enable S3 storage in Bento.</p>"},{"location":"monitoring/","title":"Bento Monitoring","text":"<p>Previously, the only way to get the logs of a given service was to connect to the the server hosting Bento and getting the logs directly from Docker. Since v17, Bento includes tools that allow authenticated and authorized users to explore the services' logs in a convenient web application.</p> <p>The stack enabling this is composed by three open-source services: - Promtail: forwards the logs from Bento's services to the log database - Loki: stores the logs from Promtail and serves them to Grafana - Grafana: auth protected web application to query and analyse collected logs</p>"},{"location":"monitoring/#configuration","title":"Configuration","text":"<p>Enable monitoring by setting the feature flag</p> <pre><code>BENTO_MONITORING_ENABLED='true'\n</code></pre> <p>Pull the images and prepare the network/directories for monitoring containers:</p> <pre><code>./bentoctl.bash pull\n./bentoctl.bash init-docker\n./bentoctl.bash init-dirs\n</code></pre> <p>Grafana is configured to only let in authenticated users from Bento's Keycloak realm,  if they have the required client permissions for Grafana.</p> <p>Create the Grafana OIDC client, its permissions and group mappings with the following:</p> <pre><code>./bentoctl.bash init-auth\n</code></pre> <p>Set the outputted value for <code>BENTO_GRAFANA_CLIENT_SECRET</code> in the <code>local.env</code> file and restart Grafana.</p> <pre><code>./bentoctl.bash restart grafana\n</code></pre>"},{"location":"monitoring/#user-management","title":"User management","text":"<p>In order for a user to access Grafana, they must belong to a Grafana sub-group in Bento's Keycloak.</p> <p>Group role-mappings in Keycloak: - Grafana (parent group, no permission)     - Admin         - Editor permissions         - Administration of Grafana     - Editor         - Viewer permissions         - Can explore logs         - Can create dashboards for viewers     - Viewer         - Can view created dashboards</p> <p>The <code>admin</code>, <code>editor</code> and <code>viewer</code> roles are Grafana concepts. During authentication, Grafana will synchronize the  user's roles from Keycloak, and only let the user in if a valid role can be retrieved from the ID token.</p> <p>The <code>init-auth</code> step in the configuration creates everything needed for this in Keycloak. </p> <p>The only remaining step is to add users to Grafana groups: - In a browser, navigate to the Keycloak admin portal (your <code>BENTOV2_AUTH_DOMAIN</code>) - Authenticate using the admin credentials - By default the realm will be <code>Keycloak</code>, change it to Bento's realm (value of <code>BENTOV2_AUTH_REALM</code>) - Navigate to the <code>Users</code> tab - Select a user - Select the user's <code>Groups</code> tab - Click on the <code>Join Group</code> button - Select a Grafana sub-group and click on <code>Join</code></p> <p></p>"},{"location":"monitoring/#using-grafana","title":"Using Grafana","text":"<p>The user can now connect to <code>bento_web</code> and access Grafana from the header tabs!</p> <p>At the moment, no default dashboards are provided, so only users with <code>admin</code> or <code>editor</code> roles will have  access to data.</p> <p>To look at the raw logs for a service: - Select the <code>Explore</code> tab in Grafana - Select the <code>service_name</code> label filter - Select a service from the value drop down - In the top-right, click on <code>run query</code>, <code>live</code>, or <code>Last &lt;time frame&gt;</code> to fetch the logs</p> <p>The logs will appear at the bottom. The log query can be further modified with operations, allowing you to fine comb your logs effectively.</p> <p></p>"},{"location":"phenopackets_v1_to_v2/","title":"Converting Phenopackets from V1 to V2 using <code>bentoctl</code>","text":"<p>Phenopackets JSON documents can be converted from V1  to V2 using <code>bentoctl</code> and  Phenopacket-tools as its backend.</p> <p>For the <code>bentoctl convert-pheno</code> command to work, you need to: 1. Download a Phenopacket-tools release. 2. Unzip its content and place the .jar file somwhere safe. 3. Specify the .jar path in <code>local.env</code> with the <code>PHENOTOOL_JAR_PATH</code> variable</p> <p>You can then convert a file with:</p> <pre><code>bentoctl convert-pheno &lt;source&gt; &lt;target&gt;\n</code></pre> <p>If the <code>target</code> argument is not provided, <code>bentoctl</code> will append \"_pheno_v2\" to the source file's name and save it in its  parent directory.</p>"},{"location":"public_discovery/","title":"Public data discovery configuration","text":"<p>New in Bento v17.</p> <p>Previously, the public data configuration given to Katsu (<code>lib/katsu/config.json</code>) was applied on all the metadata  contained in the service. This configuration declares which fields can be queried publicly for discovery purposes,  which charts to display and which censorship rules to apply on the results.</p> <p>Katsu can hold multiple projects/datasets that may use different fields, require specific charts or custom <code>extra_properties</code> schemas at the project level. Therefore, there is a need to tailor the discovery configuration at different levels to properly represent the  particularities in the information of a project or dataset.</p> <p>Bento v17 gives the ability to specify a scoped Discovery configuration at the following levels: -   Dataset     -   Optional at dataset creation     -   For scoped queries on public endpoints targeting a project and dataset:         -   Katsu will use the dataset's discovery configuration, if one exists.         -   If no configuration is found, falls back to the parent project's discovery. -   Project     -   Optional at project creation     -   For scoped queries on public endpoints targeting a project only:         -   Katsu will use the project's discovery configuration, if one exists.         -   If no configuration is found, falls back to the node's config. -   Node     -   Optional during Katsu deployment     -   Uses the legacy <code>lib/katsu/config.json</code> file mount     -   For non-scoped queries on public endpoints:         -   Katsu will use the node's discovery, if one exists.         -   If no node configuration is found, Katsu will respond with a 404 status.     -   For scoped queries on public endpoints:         -   Katsu will fallback on the node's discovery if the project and/or dataset in the scope don't have one         -   If no node configuration is found, Katsu will respond with a 404 status.</p>"},{"location":"public_discovery/#creating-a-discovery-configuration-file","title":"Creating a discovery configuration file.","text":"<p>Follow these steps in order to add public discovery for a given scope.</p> <ol> <li>Decide at which level the discovery configuration will be applied.</li> <li>Create a copy of <code>etc/katsu.config.example.json</code>, use it as a base template</li> <li>Modify the <code>fields</code> section so that it includes the fields of interest.</li> <li>Modify the <code>search</code> section, include the fields from the previous section to make them searchable</li> <li>Modify the <code>overview</code> section in order to specify which fields should be rendered as charts and how.</li> <li>Set the desired censorship rules in the <code>rules</code> section.</li> </ol> <p>The resulting JSON file needs to respect the JSON-schema defined in Katsu here.</p>"},{"location":"public_discovery/#using-a-discovery-configuration-file","title":"Using a discovery configuration file.","text":"<p>With the valid discovery configuration file in hand, you can now add it to Katsu.</p>"},{"location":"public_discovery/#apply-the-discovery-configuration-at-the-node-level","title":"Apply the discovery configuration at the node level:","text":"<p>This operation must be done by a Bento node administrator.</p> <pre><code># Move the file to Katsu's config volume\ncp &lt;discovery config JSON file&gt; ./lib/katsu/config.json\n\n# restart Katsu to load the config.\n./bentoctl.bash restart katsu\n</code></pre>"},{"location":"public_discovery/#apply-the-discovery-configuration-at-the-project-or-dataset-level","title":"Apply the discovery configuration at the project or dataset level","text":"<p>These operations must be performed in <code>bento_web</code> by an authenticated user  with the <code>edit:dataset</code>, <code>create:dataset</code>, <code>edit:project</code>, <code>create:project</code> permissions.</p> <p>Before creating/editing a project/dataset to specify a discovery configuration,  make sure that the JSON file is in Bento's dropbox.</p> <p>At project/dataset creation, leaving the discovery field empty is permitted. Specify a discovery config by selecting the desired file from the drop-down options.</p> <p></p> <p>During project/dataset editing, three radio buttons are shown, allowing the user to pick the existing value, a new value from file, or none. The 'none' option is equivalent to leaving the field empty at creation.</p> <p></p>"},{"location":"reference_material/","title":"Guide to genomic reference material in Bento","text":"<p>This document includes a bit of information on what a reference genome is, what some common ones for Bento projects are, and some subtleties that are important to pay attention to.</p>"},{"location":"reference_material/#table-of-contents","title":"Table of Contents","text":"<ul> <li>What is a reference genome?</li> <li>File representation of reference genomes</li> <li>Common reference genomes</li> <li>Aspects to pay attention to!</li> </ul>"},{"location":"reference_material/#what-is-a-reference-genome","title":"What is a reference genome?","text":"<p>Organisms of the same species share the vast majority of their DNA sequence, with variation in phenotype (appearance,  behaviour, disease susceptibility, etc.) being to a large extent the result of variation in specific loci (regions) of the individuals' genome.</p> <p>As a result, bioinformatics file formats often (but not always!) use a common set of sequences called a  \"reference genome\", and data is associated with a particular chromosome and position within this genome.</p> <p>As an example, one reference genome for humans is called \"hg38\"/\"GRCh38\". Human individuals usually have 46 chromosomes: 22 pairs of autosomes, and 1 pair of sex chromosomes (n = (22 + 1); 2n = 46 - see Figure 1). One copy of each chromosome is inherited from an individual's mother, the other from their father. The <code>hg38</code> reference genome has 24 main genomic  sequences: <code>chr1</code>-<code>chr22</code> + <code>chrX</code> + <code>chrY</code> (Table 1); we don't need pairs here, since the pairs are extremely similar to one another; any variation between them can (usually) be well-represented </p> <p></p> <p>Figure 1: A karyotype of a human male with a normal chromosome configuration.</p> hg38 chromosome length chr1 248956422 chr2 242193529 chr3 198295559 chr4 190214555 chr5 181538259 chr6 170805979 chr7 159345973 chr8 145138636 chr9 138394717 chr10 133797422 chr11 135086622 chr12 133275309 chr13 114364328 chr14 107043718 chr15 101991189 chr16 90338345 chr17 83257441 chr18 80373285 chr19 58617616 chr20 64444167 chr21 46709983 chr22 50818468 chrX 156040895 chrY 57227415 <p>Table 1: <code>hg38</code> reference genome chromosome lengths.</p> <p>It's worth noting that the nuclear genome, i.e., what is described above, is not the only genome in human cells. Humans also have mitochrondria, which have their own circular genome.  This genome, sometimes represented as <code>chrMT</code> in reference genome files, is 16569 bp long in humans.</p>"},{"location":"reference_material/#file-representation-of-reference-genomes","title":"File representation of reference genomes","text":"<p>Reference genomes are usually represented using the FASTA file format.</p> <p>Our own Bento reference service ingests FASTA files, and does all operations using the FASTA format + an index file.</p>"},{"location":"reference_material/#common-reference-genomes","title":"Common reference genomes","text":"<p>Here are some common reference genomes, and which Bento projects use them.</p>"},{"location":"reference_material/#human","title":"Human","text":"<ul> <li><code>CHM13v2.0</code>: The \"latest and greatest\"; a more contiguous reference with several gaps filled in. This genome will be   used in more projects going forward.</li> <li><code>hg38</code>/<code>GRCh38</code>: </li> <li>BQC19: The CVMFS version on Alliance clusters at      <code>/cvmfs/soft.mugqic/CentOS6/genomes/species/Homo_sapiens.GRCh38/genome/Homo_sapiens.GRCh38.fa</code></li> <li><code>hg19</code>/<code>GRCh37</code>/<code>hs37d5</code>:</li> <li>ICHANGE: The special <code>hs37d5</code> version derived from <code>GRCh37</code> is the 1000 Genomes Phase 2 reference genome.     It is on Alliance clusters at      <code>/lustre03/project/6007512/C3G/analyste_dev/genomes/species/Homo_sapiens.hs37d5/genome/Homo_sapiens.hs37d5.fa</code>.</li> </ul>"},{"location":"reference_material/#mouse","title":"Mouse","text":"<ul> <li><code>mm10</code>/<code>GRCm38</code>: an older mouse (Mus musculus) reference genome.</li> <li>ICHANGE: The CVMFS version on Alliance clusters at      <code>/cvmfs/soft.mugqic/CentOS6/genomes/species/Mus_musculus.GRCm38/genome/Mus_musculus.GRCm38.fa</code> </li> </ul>"},{"location":"reference_material/#polar-bear","title":"Polar bear","text":"<ul> <li><code>UrsMar_1.0</code>: Used by BearWatch; available from https://www.ncbi.nlm.nih.gov/assembly/GCF_000687225.1/.</li> </ul>"},{"location":"reference_material/#aspects-to-pay-attention-to","title":"Aspects to pay attention to!","text":"<ul> <li>There can be many different versions of the same base reference genome - for example, ICHANGE specifically uses the   <code>hs37d5</code> version of <code>GRCh37</code>, which DOES NOT have <code>chr</code> prefixes for the chromosomes, i.e., chromosome 1 is    represented as <code>1</code> instead of <code>chr1</code>. It is important to check which specific version is used!</li> </ul> <p>VCFs can be queried to find evidence for which reference genome was used:</p> <p><code>bash   bcftools view -h ./path/to/the.vcf.gz</code></p>"},{"location":"reverse-proxy/","title":"Bento behind a proxy","text":"<p>A Bento instance is typically deployed on a dedicated VM with a public IP address.</p> <p>By creating DNS <code>A</code> or <code>CNAME</code> records pointing hostnames to the VM's IP, deployers can obtain SSL certificates from Let's Encrypt using <code>certbot</code>.</p> <p>Having a Bento instance on a VM with a public IP is convenient in terms of deployment, but is a security trade-off, as it exposes the VM's IP and ports to attackers.</p> <p>A more secure deployment can be achieved by using a VM with no public IP to host Bento and proxy the traffic through a reverse proxy.</p>"},{"location":"reverse-proxy/#using-a-reverse-proxy-in-front-of-bento","title":"Using a reverse proxy in front of Bento","text":""},{"location":"reverse-proxy/#deployment-overview","title":"Deployment overview","text":"<p>As an example, let's assume we have the following hostnames to deploy: - Public dashboard: <code>sandbox.bento.example.com</code> - Portal: <code>portal.sandbox.bento.example.com</code> - Auth: <code>auth.sandbox.bento.example.com</code></p> <p>We will be using the following deployment infrastructure: - Bento VM (<code>bento-sandbox</code>)     - Linux VM in a private or public cloud     - On the subnet <code>private-network</code>     - Public IP: <code>NONE</code>     - Private IP: <code>10.0.0.1</code>     - DNS records: <code>NONE</code> - Reverse Proxy     - Has network access to <code>bento-sandbox (10.0.0.1)</code> on <code>private-network</code>     - Public IP: <code>some.public.ip.adr</code>     - DNS records:         - (A) <code>sandbox.bento.example.com</code> =&gt; <code>some.public.ip.adr</code>         - (A) <code>*.sandbox.bento.example.com</code> =&gt; <code>some.public.ip.adr</code>     - Manages the SSL certificates for our domains     - Proxies the requests to the <code>bento-sandbox</code> host with SSL termination         - <code>sandbox.bento.example.com</code> =&gt; <code>10.0.0.1:80</code>         - <code>*.sandbox.bento.example.com</code> =&gt; <code>10.0.0.1:80</code></p> <p> The diagram above illustrates the deployment architecture.</p> <p>With the Bento VM on a dedicated private network, we can have SSL termination at the reverse proxy in front of our Bento. As a result, all the SSL certificates can be managed at the level of the reverse proxy.</p>"},{"location":"reverse-proxy/#configure-the-bento-hosting-vm","title":"Configure the Bento hosting VM","text":"<p>To run a Bento instance in SSL termination mode:</p> <pre><code># Set feature flag in local.env\nBENTO_GATEWAY_USE_TLS='false'\n\n# Start the services\n./bentoctl.bash start\n</code></pre>"},{"location":"reverse-proxy/#configure-the-reverse-proxy","title":"Configure the reverse proxy","text":"<p>For this example, we are assuming that the reverse proxy is a Linux VM on which NGINX has been installed and configured.</p> <p>You could use another reverse proxy software of your liking, like Traefik or Caddy.  Alternatively, your reverse proxy could also be a service, like AWS's API Gateway, although this is out of scope for this demonstration.</p> <p>Assuming a reverse proxy VM with NGINX installed and started, add this configuration file to the <code>/etc/nginx/conf.d</code> directory:</p> <pre><code>map $http_upgrade $connection_upgrade {\n  default upgrade;\n  '' close;\n}\n\n# Redirect HTTP -&gt; HTTPS\nserver {\n  listen 80 ;\n  return 301 https://$host$request_uri;\n}\n\n# Reject HTTPS requests on unspecified subdomains\nserver {\n  listen 443 ssl;\n  ssl_reject_handshake on;\n}\n\nserver {\n  listen 443 ssl;\n  # Only accept \"sandbox.bento.example.com\" and auth|portal subdomains\n  server_name sandbox.bento.example.com auth.sandbox.bento.example.com portal.sandbox.bento.example.com;\n\n  # Wildcard certificate for *.sandbox.bento.example.com\n  ssl_certificate /etc/letsencrypt/live/sandbox.bento.example.com/fullchain.pem;\n  ssl_certificate_key /etc/letsencrypt/live/sandbox.bento.example.com/privkey.pem;\n\n  location / {\n    proxy_set_header    Host $host;\n    proxy_set_header    X-Real-IP $remote_addr;\n\n    # Crucial for Keycloak proxying with SSL termination\n    proxy_set_header    X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header    X-Forwarded-Proto $scheme;\n    proxy_set_header    X-Forwarded-Host $host;\n\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection $connection_upgrade;\n    proxy_http_version 1.1;\n\n    # For large requests\n    client_body_timeout     660s;\n    proxy_read_timeout      660s;\n    proxy_send_timeout      660s;\n    send_timeout            660s;\n    client_max_body_size    200m;\n\n    # Bento VM instance IP on the private network\n    # On port 80 since we use SSL termination\n    proxy_pass  http://10.0.0.1:80;\n    proxy_redirect  default;\n\n  }\n\n}\n</code></pre> <p>Then restart the NGINX server to load the new configuration.</p> <p>If everything was done correctly, you should now be able to reach the Bento instance through the reverse-proxy!</p>"},{"location":"reverse-proxy/#proxying-multiple-bento-instances","title":"Proxying multiple Bento instances","text":"<p>If more Bento instances are needed, the same reverse proxy can be used to route traffic.</p> <p>To do so, one would simply need to: 1. Create and configure a Bento VM on a private network accesible by the reverse-proxy 2. Create new DNS records for the desired domains     1. Not necessary if using wildcard DNS records already covering the domain 3. Obtain the certificates for the desired domains on the reverse proxy    1. Or use wildcard certificates (recommended) 4. Configure the reverse proxy to route traffic to the new instance    1. Add a conf to <code>/etc/nginx/conf.d/</code>    2. Restart the reverse proxy</p>"},{"location":"troubleshooting/","title":"Troubleshooting Bento","text":"<p>Common issues can arise when developing on Bento, or when deploying it to a server.  This document lists known pitfalls that can be encountered and their solutions.</p>"},{"location":"troubleshooting/#basics","title":"Basics","text":"<p>Useful commands used to diagnose and fix issues.</p>"},{"location":"troubleshooting/#accessing-service-logs","title":"Accessing service logs","text":"<p>When a service is not behaving as expected, checking the service's logs for errors and warnings is always a good reflex.</p> <p>The logs for each individual service can be accessed by running</p> <pre><code>./bentoctl.bash logs &lt;service&gt;\n</code></pre> <p>for example:</p> <pre><code>./bentoctl.bash logs katsu\n</code></pre> <p>If you want to follow the logs live, append the <code>-f</code> option. If no service is specified, logs from all running Docker containers will be shown.</p>"},{"location":"troubleshooting/#restarting-all-services","title":"Restarting all services","text":"<p>In some situations you may want to stop all services, perform environment changes or maintenance operations, then start all services again. To restart all services quickly</p> <pre><code># Stop all services\n./bentoctl.bash stop all\n\n# Perform maintenance operations on host (optional)\ngit pull\n./bentoctl.bash pull\n\n# Start all services\n./bentoctl.bash run all\n</code></pre> <p>One can also start and stop services individually, e.g.:</p> <pre><code>./bentoctl.bash run drs\n./bentoctl.bash stop katsu\n</code></pre>"},{"location":"troubleshooting/#docker","title":"Docker","text":"<p>Issues related to Docker.</p>"},{"location":"troubleshooting/#mounted-files","title":"Mounted files","text":"<p>How to notice: A service is experiencing issues and logs reveal it is trying to load a directory as a file.</p> <p>Confirguration files for some services are provided to the container as file mounts,  such as Katsu's <code>config.json</code> file.</p> <p>If the docker-compose of a service has a file mount that does not exsit on the host (e.g. <code>lib/katsu/config.json</code>),  Docker's default behaviour is to create a directory with said path.</p> <p>This can lead the service to experience errors when trying to load the directory as a file. To fix this: 1.  Stop the service with: <code>bentoctl stop &lt;service name&gt;</code> 2.  Make sure the expected file exists in the host's path. 3.  Start the service with: <code>bentoctl run &lt;service name&gt;</code> 4.  Check the logs for errors: <code>bentoctl logs &lt;service name&gt;</code></p>"},{"location":"troubleshooting/#permission-issues-in-volumes","title":"Permission issues in volumes","text":"<p>How to notice: Services are experiencing errors because they are unable to read the contents of their volumes.</p> <p>This is often a permission being denied because the host paths of volumes are owned by <code>root</code>, verify with: </p> <pre><code>ls -la ${BENTO_SLOW_DATA_DIR} # For \"slow\" data volumes\nls -la ${BENTO_FAST_DATA_DIR} # For \"fast\" data volumes\nls -la lib/ # For configuration volumes\n</code></pre> <p>Find the faulty path(s) and the services they are associated with. Stop any service that is using said path(s), then change the ownership with:</p> <pre><code>sudo chown -R &lt;username&gt;:&lt;username&gt; &lt;path&gt;\n</code></pre> <p>Where <code>username</code> is your username.</p> <p>Finally, start the stopped services: <code>bentoctl run &lt;service&gt;</code></p>"},{"location":"migration/migrating_to_12/","title":"Migrating to Bento v12","text":"<p>The following is a migration guide for going from Bento v2.11 to Bento v12.</p> <p>Note the change in versioning scheme for this release; we dropped the <code>2.</code> prefix.</p>"},{"location":"migration/migrating_to_12/#1-update-docker-containers","title":"1. Update Docker containers","text":"<p>The following commands:</p> <ul> <li>Stop the cluster</li> <li>Pull the latest images</li> <li>Re-initialize Docker networks</li> <li>Start the cluster again</li> </ul> <pre><code>./bentoctl.bash stop\n./bentoctl.bash pull\n./bentoctl.bash init-docker\n./bentoctl.bash run\n</code></pre>"},{"location":"migration/migrating_to_12/#2-convert-the-keycloak-client-to-be-public-and-enable-pkce","title":"2. Convert the Keycloak client to be <code>public</code> and enable PKCE","text":"<p>To do this, sign in to Keycloak as an administrator and navigate to the realm &amp; Bento client. Then, turn off \"Client authentication\" and make sure the settings are as follows, with only \"Standard flow\" enabled and save your changes.</p> <p></p> <p>Then, make sure to set a valid post-logout redirect URI if not already done. Use the value  <code>https://portal.bentov2.local/*</code>, replacing the domain with whatever your portal URL is:</p> <p></p> <p>Then, enable PKCE by going to the \"Advanced\" tab, scrolling down to \"Advanced settings\", and setting the <code>Proof Key for Code Exchange Code Challenge Method</code> setting to <code>S256</code>. Finally, save your changes again.</p> <p>In this tab, make sure \"Access Token Lifespan\" is also set to a finite value. As a default, use something short, like 15 minutes.</p> <p>To clean up your <code>local.env</code> file, remove the entry that looks like this:</p> <pre><code>CLIENT_SECRET=some-secret-here\n</code></pre>"},{"location":"migration/migrating_to_12/#3-create-a-new-client-for-any-bots-if-needed","title":"3. Create a new client for any bots (if needed)","text":"<p>In Keycloak, create separate clients for any bots. These should have \"Client authentication\" ON.</p> <p>For the legacy bot authentication method, \"Direct access grants\" will need to be ON as well.</p> <p>For a more modern bot approach, turn \"Direct access grants\" OFF and turn \"Service account roles\" ON, thereby enabling the \"Client credentials\" authentication flow.</p>"},{"location":"migration/migrating_to_12/#4-create-superuser-permissions-in-the-new-bento-authorization-service","title":"4. Create superuser permissions in the new Bento authorization service","text":"<p>First, open a shell in the authorization service container:</p> <pre><code>./bentoctl.bash shell authz\n</code></pre> <p>Then, run the following command for each user ID you wish to assign superuser permissions to:</p> <pre><code>bento_authz assign-all-to-user iss sub\n</code></pre> <p>Where <code>iss</code> is the issuer (for example, <code>https://bentov2auth.local/realms/bentov2</code>) and <code>sub</code> is the user (subject) ID, which in Keycloak should be a UUID.</p>"},{"location":"migration/migrating_to_12/#optional-second-step-assign-portal-access-to-all-users-in-the-instance-realm","title":"Optional second step: Assign portal access to all users in the instance realm","text":"<p>We added a special permission, <code>view:private_portal</code>, to Bento v12 in order to carry forward the current 'legacy' authorization behaviour for one more major version. This permission currently behaves as a super-permission, allowing all actions within the private portal. However, in the future, this permission will do almost nothing.</p> <p>To carry forward legacy behaviour of all users in the instance realm being able to do everything, run the following command in the authorization service container:</p> <pre><code># Create the grant\nbento_authz create grant \\\n  '{\"iss\": \"ISSUER_HERE\", \"client\": \"WEB_CLIENT_ID_HERE\"}' \\\n  '{\"everything\": true}' \\\n  'view:private_portal'\n</code></pre>"},{"location":"migration/migrating_to_12/#5-create-bot-permissions-in-the-new-bento-authorization-service-if-needed","title":"5. Create bot permissions in the new Bento authorization service (if needed)","text":"<p>First, open a shell in the authorization service container if you don't already have one from the step(s) before:</p> <pre><code>./bentoctl.bash shell authz\n</code></pre> <p>Then, run the following commands for each bot client you wish to assign ingest permissions to:</p> <pre><code># This grant is a temporary hack to get permissions working for v12. In the future, it should be removed.\nbento_authz create grant \\\n  '{\"iss\": \"ISSUER_HERE\", \"client\": \"BOT_CLIENT_ID_HERE\"}' \\\n  '{\"everything\": true}' \\\n  'view:private_portal'\n\n# This grant is not used currently, but ensures future permission to ingest data into the project \n# and clear existing data to make room for the new ingested data.\nbento_authz create grant \\\n  '{\"iss\": \"ISSUER_HERE\", \"client\": \"BOT_CLIENT_ID_HERE\"}' \\\n  '{\"project\": \"my-automated-project-id\"}' \\\n  'view:runs' 'ingest:data' 'delete:data'\n</code></pre>"},{"location":"migration/migrating_to_13/","title":"Migrating to Bento v13","text":"<p>The following is a migration guide for going from Bento v12.x to Bento v13.</p> <p>Some notes on breaking changes in this version:</p> <ul> <li>WES now requires its own OAuth2 client ID/secret for making authorized requests</li> <li>The concept of 'tables' has been removed from Bento; some data re-ingestion will be required</li> </ul>"},{"location":"migration/migrating_to_13/#1-delete-variant-data","title":"1. Delete variant data","text":"<p>Since the concept of 'tables' has been removed from Bento v13;  data re-ingestion will be required for all variant data via the UI.</p> <p>It would be wise to first remove the Gohan Elasticsearch volume to clean up old variant data on the VM.</p>"},{"location":"migration/migrating_to_13/#2-pull-latest-docker-containers-and-stop-bento","title":"2. Pull latest Docker containers and stop Bento","text":"<p>The following commands:</p> <ul> <li>Stop the cluster</li> <li>Pull the latest images</li> </ul> <pre><code>./bentoctl.bash stop\n./bentoctl.bash pull\n</code></pre>"},{"location":"migration/migrating_to_13/#3-create-a-wes-client-with-secret","title":"3. Create a WES client with secret","text":"<p>WES now requires its own OAuth2 client ID/secret for making authorized requests to various services within WDL workflows. </p> <p>To create this client, with secret, re-run the <code>init-auth</code> subcommand of <code>bentoctl</code>:</p> <pre><code>./bentoctl.bash init-auth\n</code></pre> <p>This will print the new client secret to the console; set it in your <code>local.env</code> file similar to the following:</p> <pre><code># ...\nBENTO_WES_CLIENT_SECRET=my-wes-client-secret-here\n# ...\n</code></pre> <p>The default client ID here is <code>wes</code>, as set in <code>./etc/default_config.env</code>.</p>"},{"location":"migration/migrating_to_13/#4-restart-bento","title":"4. Restart Bento","text":"<p>Now that we have the environment configured correctly, we can restart the  Bento instance:</p> <pre><code>./bentoctl.bash run\n</code></pre>"},{"location":"migration/migrating_to_13/#5-create-a-grant-for-the-wes-oauth2-client","title":"5. Create a grant for the WES OAuth2 client","text":"<p>The next step is to create a grant in <code>authz</code> which gives WES the ability to ingest data into all projects/endpoints/etc. in the node:</p> <pre><code>./bentoctl.bash shell authz  # enter into an authz container session to create the grant\n\n# This grant is a temporary hack to get permissions working for v12/v13. In the future, it should be removed.\nbento_authz create grant \\\n  '{\"iss\": \"ISSUER_HERE\", \"client\": \"wes\"}' \\\n  '{\"everything\": true}' \\\n  'view:private_portal'\n\n# This grant gives permission to access and ingest data into all projects\nbento_authz create grant \\\n  '{\"iss\": \"ISSUER_HERE\", \"client\": \"wes\"}' \\\n  '{\"everything\": true}' \\\n  'query:data' 'ingest:data'\n</code></pre>"},{"location":"migration/migrating_to_13/#6-delete-and-re-ingest-gohan-variant-data","title":"6. Delete and re-ingest Gohan variant data","text":"<p>Since you should have deleted all variant data in step 1, now is the time to re-ingest VCFs into Goahn.</p>"},{"location":"migration/migrating_to_14/","title":"Migrating to Bento v14","text":"<p>Version 14 has removed all MCODE support. MCODE-specific properties on Individuals in Katsu have been moved to <code>extra_properties</code>.</p> <p>Updating to Bento 14 should be as straightforward as:</p> <pre><code>git pull\n./bentoctl.bash start --pull\n</code></pre>"},{"location":"migration/migrating_to_15/","title":"Migrating to Bento v15","text":"<p>Bento v15 migrates to Phenopackets v2, and as such requires that Phenopackets are updated and re-ingested.</p> <p>This version also adds the reference service, so permissions must be updated in order to give reference service permissions to administrators and the WES client.</p>"},{"location":"migration/migrating_to_15/#1-pre-update-data-removal","title":"1. Pre-update data removal","text":"<p>Before updating, perform the following steps:</p> <ul> <li>Shut down Bento with <code>./bentoctl.bash stop</code></li> <li>Remove the Katsu data volume</li> <li>Remove the WES data volume</li> </ul>"},{"location":"migration/migrating_to_15/#2-update-images","title":"2. Update images","text":"<pre><code>./bentoctl.bash pull\n</code></pre>"},{"location":"migration/migrating_to_15/#3-create-new-docker-volume-directories-and-networks","title":"3. Create new Docker volume directories and networks","text":"<pre><code>./bentoctl.bash init-docker  # new networks for reference and reference-db\n./bentoctl.bash init-dirs  # new volume directory for DRS temporary files\n</code></pre>"},{"location":"migration/migrating_to_15/#4-set-new-environment-variables","title":"4. Set new environment variables","text":"<p>In <code>local.env</code>, set a secure value for <code>BENTO_REFERENCE_DB_PASSWORD</code>.</p>"},{"location":"migration/migrating_to_15/#5-restart-bento","title":"5. Restart Bento","text":"<pre><code>./bentoctl.bash start\n</code></pre>"},{"location":"migration/migrating_to_15/#6-add-permissions","title":"6. Add permissions","text":"<p>Add permissions as needed for reference service content management:</p> <pre><code>./bentoctl.bash shell authz  # start a shell session in the authz service container to access the authz CLI\nbento_authz list grants\n# In this list, find the grant IDs for the existing superuser/permissions managers and WES \nbento_authz add-grant-permissions &lt;superuser-grant-id&gt; ingest:reference_material delete:reference_material\nbento_authz add-grant-permissions &lt;wes-grant-id&gt; ingest:reference_material delete:reference_material\n</code></pre>"},{"location":"migration/migrating_to_15_1/","title":"Migrating to Bento v15.1","text":"<p>Migrating to version 15.1 from version 15 should be straightforward.</p>"},{"location":"migration/migrating_to_15_1/#1-update-bentoctl-python-requirements","title":"1. Update <code>bentoctl</code> Python requirements","text":"<p>Make sure you've entered into the <code>bentoctl</code> Python virtual environment, if you've set one up:</p> <pre><code>source env/bin/activate\n</code></pre> <p>Then, install the latest requirements / module versions:</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"migration/migrating_to_15_1/#2-update-services-and-restart","title":"2. Update services and restart","text":"<p>Run the following commands to pull the latest service images and restart services as needed:</p> <pre><code>./bentoctl.bash pull\n./bentoctl.bash start\n</code></pre>"},{"location":"migration/migrating_to_15_2/","title":"Migrating to Bento v15.2","text":"<p>Migrating to version 15.2 from version 15.1 should be straightforward.</p>"},{"location":"migration/migrating_to_15_2/#1-update-gohan-jvm-configuration-if-necessary","title":"1. Update Gohan JVM configuration, if necessary","text":"<p>See the relevant section in the installation guide for more information.</p>"},{"location":"migration/migrating_to_15_2/#2-update-services-and-restart","title":"2. Update services and restart","text":"<p>Run the following commands to pull the latest service images and restart services as needed:</p> <pre><code>./bentoctl.bash pull\n./bentoctl.bash restart\n</code></pre>"},{"location":"migration/migrating_to_16/","title":"Migrating to Bento v16","text":"<p>Key points:</p> <ul> <li>Bento v16 may now use 2 data directories for better resource usage in production.</li> <li>The environment variable <code>BENTOV2_ROOT_DATA_DIR</code> was replaced with:<ul> <li><code>BENTO_FAST_DATA_DIR</code> for SSD mounts</li> <li><code>BENTO_SLOW_DATA_DIR</code> for HDD mounts</li> </ul> </li> <li>By default, <code>Drop-Box</code> and <code>DRS</code> are now configured to use <code>BENTO_SLOW_DATA_DIR</code> as their data directory.     All other services use <code>BENTO_FAST_DATA_DIR</code>.</li> <li>If needed, the default service specific volume directories defined in <code>bento.env</code> can be overriden in your     <code>local.env</code>.</li> <li>The WES schema has been updated, so the run database must be cleared.</li> <li>The reference service has been updated, so an SQL migration must be run.</li> <li>The reference service now supports GFF3 (gene feature annotation) files, and the private portal has moved to using   this service to provide gene information for searching and track visualization. All annotations required should be   ingested/attached to the reference genome.</li> <li>Docker requirements for deployment have changed.</li> <li>Docker &gt;= 24.0.4</li> <li>Docker Compose &gt;= 2.20.0 (plugin)</li> <li>Update the versions on the host machine accordingly</li> </ul>"},{"location":"migration/migrating_to_16/#1-run-reference-service-pre-migration-step","title":"1. Run reference service pre-migration step","text":"<pre><code>./bentoctl.bash shell reference-db\nPGPASSWORD=\"${POSTGRES_PASSWORD}\"\npsql --user \"${POSTGRES_USER}\" reference\n</code></pre> <p>Then, begin a transaction:</p> <pre><code>BEGIN TRANSACTION;\n</code></pre> <p>Then, paste the contents of migrate_v0_2.sql from the reference service repository into the SQL command line.</p> <p>Next, commit the results of the transaction:</p> <pre><code>COMMIT;\n</code></pre> <p>Finally, exit the shell (via successive <code>^D</code>).</p>"},{"location":"migration/migrating_to_16/#2-stop-bento","title":"2. Stop Bento","text":"<pre><code>./bentoctl.bash stop\n</code></pre>"},{"location":"migration/migrating_to_16/#3-pre-update-data-config","title":"3. Pre-update data config","text":"<p>Before updating, perform the following steps:</p> <ul> <li>Shut down Bento with <code>./bentoctl.bash stop</code></li> <li>In <code>local.env</code>, replace <code>BENTOV2_ROOT_DATA_DIR</code> with <code>BENTO_FAST_DATA_DIR</code> and <code>BENTO_SLOW_DATA_DIR</code></li> </ul> <p>To minimize side effects in local environments, we recommend that you use the same directory as before for both new variables.</p> <pre><code># local.env\n\n# Old\nBENTOV2_ROOT_DATA_DIR=some_dir\n\n# Recommended new variables\nBENTO_FAST_DATA_DIR=some_dir\nBENTO_SLOW_DATA_DIR=some_dir\n</code></pre> <p>IMPORTANT: If you decide to split the data in distinct directories, make sure to migrate the data accordingly.</p>"},{"location":"migration/migrating_to_16/#4-update-images","title":"4. Update images","text":"<pre><code>./bentoctl.bash pull\n</code></pre>"},{"location":"migration/migrating_to_16/#5-create-new-docker-volume-directories","title":"5. Create new Docker volume directories","text":"<pre><code>./bentoctl.bash init-dirs  # new volume directory for DRS and Reference temporary files\n</code></pre>"},{"location":"migration/migrating_to_16/#6-migrate-data-from-old-bentov2_root_data_dir-location-to-bento_fast_data_dirbento_slow_data_dir","title":"6. Migrate data from old <code>BENTOV2_ROOT_DATA_DIR</code> location to <code>BENTO_FAST_DATA_DIR</code>/<code>BENTO_SLOW_DATA_DIR</code>","text":"<p>This is only needed if the data was split into distinct directories in part 1. All service data should be copied into the corresponding locations as specified in <code>etc/bento.env</code>.</p>"},{"location":"migration/migrating_to_16/#7-restart-bento","title":"7. Restart Bento","text":"<pre><code>./bentoctl.bash start\n</code></pre>"},{"location":"migration/migrating_to_16/#8-if-needed-ingest-gene-features","title":"8. If needed, ingest gene features","text":"<p>Use the ingestion workflows now provided by the reference service to either ingest a reference genome FASTA with a corresponding GFF3 file, or ingest a GFF3 file to attach to an existing reference genome.</p> <p>Do this if the instance was previously using the Gohan gene catalog.</p>"},{"location":"migration/migrating_to_17/","title":"Migrating to Bento v17","text":"<p>Key points:</p> <ul> <li>Bento now has observability tools to help monitor the services (Grafana). Some setup is required for this feature to   work.</li> <li>Katsu discovery endpoints now have an authorization layer.</li> <li>Data that used to be completely public by default (i.e.,     censored counts) now requires a permission (<code>query:project_level_counts</code> and/or <code>query:dataset_level_counts</code>), and     thus a grant in the authorization service.</li> <li>Beacon now requires a client ID/secret and an authorization service grant to access uncensored data.</li> <li>Katsu discovery is now more granular, and can be configured to the project or dataset level, in addition to the   instance level. See the Public data discovery configuration document for more information.</li> <li>...</li> </ul>"},{"location":"migration/migrating_to_17/#1-stop-bento","title":"1. Stop Bento","text":"<pre><code>./bentoctl.bash stop\n</code></pre>"},{"location":"migration/migrating_to_17/#2-checkout-to-v17-and-pull-new-docker-images","title":"2. Checkout to v17 and pull new Docker images","text":"<pre><code># Checkout on the v17 tag\ngit checkout v17\n# Pull new Docker images\n./bentoctl.bash pull\n</code></pre>"},{"location":"migration/migrating_to_17/#3-set-up-credentials-for-aggregationbeacon-and-optionally-set-up-grafana","title":"3. Set up credentials for aggregation/Beacon and, optionally, set up Grafana","text":"<p>If you wish to enable Grafana, you first must enable the monitoring feature in your <code>local.env</code> file:</p> <pre><code>BENTO_MONITORING_ENABLED='true'\n</code></pre> <p>After enabling the Grafana feature flag for the first time, you must initialize the Docker networks and mounted directories.</p> <pre><code># Init new Docker networks and directories if using Grafana\n./bentoctl.bash init-docker\n./bentoctl.bash init-dirs\n</code></pre> <p>To create the client secrets for aggregation/Beacon and Grafana (if the latter is enabled), run the following commands:</p> <pre><code>./bentoctl.bash run auth &amp;&amp; ./bentoctl.bash run gateway\n./bentoctl.bash init-auth\n</code></pre> <p>Reminder: Make sure to put the client secret(s) generated by <code>init-auth</code> into your <code>local.env</code> file!</p> <p>Aggregation/Beacon data access authorization will not work until an authorization service grant is configured; see step 4 below.</p> <p>Grafana will not be accessible to users until they are given a valid role; see the monitoring user management section for details.</p>"},{"location":"migration/migrating_to_17/#4-set-up-aggregationbeacon-permissions-and-public-data-access-grants","title":"4. Set up aggregation/Beacon permissions and public data access grants","text":"<p>Now that Beacon uses a client ID/secret to get authorized, uncensored data access for discovery, a grant must be configured to give the aggregation/Beacon client data access.</p> <p>Another change to permissions: starting from Bento v17, anonymous visitors do not have access to see censored counts data by default, even if a discovery configuration has been set up. For anonymous visitors to access data, a level (<code>bool</code>, <code>counts</code>, <code>full</code>) must be chosen and passed to the <code>bento_authz</code> CLI command below.</p> <pre><code>./bentoctl.bash run authz\n./bentoctl.bash shell authz\n\n# Configure aggregation/Beacon permissions\n# ----------------------------------------\n# This assumes the aggregation/Beacon client ID is \"aggregation\".\n# &lt;ISSUER_HERE&gt; MUST be replaced with your actual issuer value.\n#  - The query:data permission gives access to Katsu endpoints which are properly authz-enabled.\n#  - The view:private_portal permission gives access to Katsu and Gohan endpoints where the proxy still manages access.\n#    This permission will be removed in an uncoming version.\nbento_authz create grant \\\n  '{\"iss\": \"&lt;ISSUER_HERE&gt;\", \"client\": \"aggregation\"}' \\\n  '{\"everything\": true}' \\\n  'query:data' 'view:private_portal'\n\n# Configure public data access\n# ----------------------------\n# The level below (\"counts\") preserves previous functionality. Other possible options are:\n#  - none - will do nothing.\n#  - bool - for censored true/false discovery, but in effect right now forbids access.\n#  - counts - for censored count discovery.\n#  - full - allows full data access (record-level, including sensitive data such as IDs), uncensored counts, etc.\nbento_authz public-data-access counts\n</code></pre>"},{"location":"migration/migrating_to_17/#5-optionally-add-beacon-network","title":"5. Optionally, add Beacon network","text":"<p>To host a network of beacons, with a corresponding UI in Bento Public, first copy the config file:</p> <pre><code>./bentoctl.bash init-config beacon-network\n</code></pre> <p>then update values at <code>lib/beacon/config/beacon_network_config.json</code>. Activate the network by adding (or modifying) this value in local.env:</p> <pre><code>BENTO_BEACON_NETWORK_ENABLED='true'\n</code></pre>"},{"location":"migration/migrating_to_17/#6-start-bento","title":"6. Start Bento","text":"<pre><code>./bentoctl.bash start\n</code></pre>"},{"location":"migration/migrating_to_17_1/","title":"Migrating to Bento v17.1","text":"<p>Migrating to version 17.1 from version 17 should be straightforward. Check out our new documentation on using a reverse proxy in front of Bento!</p>"},{"location":"migration/migrating_to_17_1/#1-update-services-and-restart","title":"1. Update services and restart","text":"<p>Run the following commands to pull the latest service images and restart services as needed:</p> <pre><code>./bentoctl.bash pull\n./bentoctl.bash start\n</code></pre>"},{"location":"migration/migrating_to_18/","title":"Migrating to Bento v18","text":"<ul> <li>Bento v18 implements some new features for branding, which may require changes as described below.</li> <li>It also adds MinIO as a backend for future S3-compatible object storage.</li> <li>This can be enabled now, but will not be used until a future version.</li> <li>For instances hosted on the Secure Data for Health (SD4H) infrastructure, the SD4H object store should be used for     production instances when S3-compatible services become ready in a future version.</li> </ul>"},{"location":"migration/migrating_to_18/#1-stop-and-update-services-and-initialize-new-networks","title":"1. Stop and update services, and initialize new networks","text":"<pre><code>./bentoctl.bash stop\n./bentoctl.bash pull\n# set up new Docker networks for MinIO (needed even if MinIO is not set up)\n./bentoctl.bash init-docker\n</code></pre>"},{"location":"migration/migrating_to_18/#2-set-up-light-and-dark-background-branding-for-bento-public","title":"2. Set up light and dark-background branding for Bento Public","text":"<ul> <li>Make sure <code>lib/public/branding.png</code> and <code>lib/web/branding.png</code> are images which work on dark backgrounds.</li> <li>If you have a light-background logo to add: put this file at <code>lib/public/branding.lightbg.png</code>.</li> <li>If you do not have a light-background logo: run <code>./bentoctl.bash init-web public</code> to copy the Bento logo to the   above location, or copy <code>branding.png</code> to <code>branding.lightbg.png</code></li> </ul>"},{"location":"migration/migrating_to_18/#3-if-desired-disable-bento-public-sign-in-portal-links","title":"3. If desired, disable Bento Public sign in / portal links","text":"<p>Version 18 includes two new Bento Public environment variables for customizing an instance:</p> <ul> <li><code>BENTO_PUBLIC_SHOW_PORTAL_LINK</code>: Whether to show a link to the private data portal in the header</li> <li><code>BENTO_PUBLIC_SHOW_SIGN_IN</code>: Whether to show a \"Sign In\" button in the header</li> <li><code>BENTO_PUBLIC_FORCE_CATALOGUE</code>: Whether to force the data catalogue to display, even with only a single project.</li> </ul> <p>The first two are set to <code>true</code> by default, and the last is set to <code>false</code>. If desired, they can be toggled to non-default settings by modifying <code>local.env</code>, for example:</p> <pre><code># ...\nBENTO_PUBLIC_SHOW_PORTAL_LINK='false'\nBENTO_PUBLIC_SHOW_SIGN_IN='false'\nBENTO_PUBLIC_FORCE_CATALOGUE='true'\n# ...\n</code></pre>"},{"location":"migration/migrating_to_18/#4-enabling-minio","title":"4. Enabling MinIO","text":"<p>To enable the deployment of a MinIO server for S3 storage, refer to the documentation on configuring MinIO for Bento.</p>"},{"location":"migration/migrating_to_18/#5-restart-services","title":"5. Restart services","text":"<pre><code>./bentoctl.bash start\n</code></pre>"},{"location":"migration/migrating_to_19/","title":"Migrating to Bento v19","text":"<p>TODO</p>"},{"location":"migration/migrating_to_2_11/","title":"Migrating to BentoV2 2.11","text":"<p>BentoV2 2.11 introduces a new pre-built gateway image, a new Keycloak image version, and a new management tool called <code>bentoctl</code> which replaces the Makefile.</p>"},{"location":"migration/migrating_to_2_11/#shut-down-the-old-cluster","title":"Shut down the old cluster","text":"<p>The Makefile will likely no longer work, so stop the containers using the <code>docker</code> command or GUI.</p>"},{"location":"migration/migrating_to_2_11/#move-certificates","title":"Move certificates","text":"<p>Certificates have been relocated from <code>lib/gateway/certs</code> to <code>./certs</code>, since Keycloak now terminates SSL at the Keycloak server itself instead of the gateway.</p> <p>To move certs, run:</p> <pre><code>mv ./lib/gateway/certs/* ./certs/\n</code></pre>"},{"location":"migration/migrating_to_2_11/#move-development-repos-optional-can-just-let-bentoctl-re-clone-instead","title":"Move development repos (optional; can just let <code>bentoctl</code> re-clone instead)","text":"<p>Development repositories are now located in <code>./repos</code>.</p> <p>Repositories should be relocated and renamed after the <code>docker compose</code> service name. For example, for web:</p> <pre><code>mv lib/web/bento_web repos/web\n</code></pre>"},{"location":"migration/migrating_to_2_11/#updating-local-environment-variables","title":"Updating local environment variables","text":"<p>A new configuration variable has been added in BentoV2 2.11.  Here is what you will need to set in your <code>local.env</code> file:</p> <pre><code># Set this to a random secret value\nBENTOV2_SESSION_SECRET=some-long-random-string\n\n# These used to be set by default in bento.env, but now needs explicit setting in local.env\nBENTOV2_KATSU_APP_SECRET=some-long-random-string\nBENTOV2_KATSU_DB_PASSWORD=some-long-random-string\n\n# This used to be set by default in bento.env; same as above\nBENTOV2_GOHAN_ES_PASSWORD=some-long-random-string\n</code></pre> <p>Remove any lines which look like the following:</p> <pre><code>BENTOV2_FEDERATION_PROD_DEBUG=true\nBENTOV2_FEDERATION_DEV_DEBUG=true\n</code></pre> <p>The default development value for <code>BENTOV2_ROOT_DATA_DIR</code> was changed to <code>./data</code>; this should not affect an existing setup.</p>"},{"location":"migration/migrating_to_2_11/#create-a-python-38-preferably-310-virtual-environment-and-install-bentoctl-requirements","title":"Create a Python 3.8+ (preferably 3.10+) virtual environment and install <code>bentoctl</code> requirements","text":"<p><code>bentoctl</code> is a Python script, and requires some external dependencies, which we can put in a virtual environment.</p> <pre><code>python3 -m venv ./env  # create env folder with virtual environment inside\nsource ./env/bin/activate  # activate the virtual environment\npip install -r requirements.txt  # install bentoctl requirements\n./bentoctl.bash --help  # Make sure bentoctl works and look at the available commands\n</code></pre>"},{"location":"migration/migrating_to_2_11/#make-bentoctl-alias-optional-linuxmacos","title":"Make <code>bentoctl</code> alias (optional; Linux/macOS)","text":"<p>To make interacting with the CLI quicker, consider adding an alias for calling <code>bentoctl.bash</code>, putting the following in your <code>.bash_aliases</code>, <code>.bash_profile</code> or <code>.zshrc</code> file:</p>"},{"location":"migration/migrating_to_2_11/#bashzsh","title":"Bash/ZSH:","text":"<pre><code>alias bentoctl=\"./bentoctl.bash\"\n</code></pre> <p>From here, you can use <code>bentoctl</code> instead of <code>./bentoctl.bash</code> to manage BentoV2.</p>"},{"location":"migration/migrating_to_2_11/#install-docker-compose-plugin-if-needed","title":"Install Docker Compose Plugin (if needed)","text":"<p>On Ubuntu, for example:</p> <pre><code>apt-get install docker-compose-plugin\n</code></pre> <p>See this StackOverflow post.</p>"},{"location":"migration/migrating_to_2_11/#create-new-docker-networks","title":"Create new Docker networks","text":"<p>v2.11 adds several new Docker networks in an effort to better isolate services from each other to provide better security. To create these if needed, run:</p> <pre><code>./bentoctl.bash init-docker\n</code></pre> <p>Don't worry; this is idempotent and will not fail if any required network already exists.</p>"},{"location":"migration/migrating_to_2_11/#pull-new-images","title":"Pull new images","text":"<p>v2.11 needs a bunch of new service images, as specified by <code>etc/bento.env</code>. To update the images using the new <code>bentoctl</code> tool, run:</p> <pre><code>./bentoctl.bash pull\n</code></pre>"},{"location":"migration/migrating_to_2_11/#start-the-new-cluster","title":"Start the new cluster","text":"<pre><code>./bentoctl.bash run\n</code></pre>"},{"location":"migration/migrating_to_2_11/#migrating-to-bentoctl","title":"Migrating to <code>bentoctl</code>","text":"<p>Key changes versus the Makefile include:</p>"},{"location":"migration/migrating_to_2_11/#running-all-services","title":"Running all services","text":"<p>Makefile: <code>make run-all</code></p> <p><code>bentoctl</code>: <code>./bentoctl.bash run</code></p>"},{"location":"migration/migrating_to_2_11/#restarting-a-specific-service-while-pulling-a-new-image","title":"Restarting a specific service, while pulling a new image","text":""},{"location":"migration/migrating_to_2_11/#makefile","title":"Makefile","text":"<pre><code>make stop-drs\ndocker pull ghcr.io/bento-platform/...\nmake run-drs\n</code></pre>"},{"location":"migration/migrating_to_2_11/#bentoctl","title":"<code>bentoctl</code>","text":"<pre><code>./bentoctl.bash restart --pull drs\n</code></pre>"},{"location":"migration/migrating_to_2_11/#switching-a-service-eg-web-to-development-mode","title":"Switching a service (e.g., <code>web</code>) to development mode","text":""},{"location":"migration/migrating_to_2_11/#makefile_1","title":"Makefile","text":"<pre><code>make clean-web\nmake run-web-dev\n</code></pre>"},{"location":"migration/migrating_to_2_11/#bentoctl_1","title":"<code>bentoctl</code>","text":"<p>Note: that the first time <code>work-on</code> is called, it will clone the service in question in the <code>repos/</code> directory  and run the version of the service that code specifies. This is a change from the old approach, where the repos were located in <code>lib/</code>.</p> <pre><code>./bentoctl.bash work-on web\n</code></pre> <p>This will automatically restart the service in a local development mode, using code in <code>./repos/web</code>.</p>"},{"location":"migration/migrating_to_2_11/#switching-a-service-eg-web-to-pre-built-mode","title":"Switching a service (e.g., <code>web</code>) to pre-built mode","text":""},{"location":"migration/migrating_to_2_11/#makefile_2","title":"Makefile","text":"<pre><code>make clean-web-dev\nmake run-web\n</code></pre>"},{"location":"migration/migrating_to_2_11/#bentoctl_2","title":"<code>bentoctl</code>","text":"<pre><code>./bentoctl.bash prebuilt web\n</code></pre> <p>This will start in either production mode (if <code>MODE=prod</code> in <code>local.env</code>) or development mode, but with a  pre-built image, if <code>MODE=dev</code>.</p>"},{"location":"migration/migrating_to_2_11/#notes-on-cbioportal-usage","title":"Notes on cBioPortal Usage","text":"<p>If you want to use cBioPortal (which is partially integrated into 2.11), you will need to add the cBioPortal URL (with <code>/*</code>) as valid redirect URI and, plain, as a valid web origin:</p> <pre><code>redirect URIs: [..., https://cbioportal.my-bento-domain/*]  # Note: /*\nweb origins: [..., https://cbioportal.my-bento-domain]  # Note: no trailing slash\n</code></pre> <p>Also, if developing locally, you should regenerate certificates so that a cBioPortal self-signed certificate is generated.</p>"}]}